{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "context_experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmqnzZKBKQ7W"
      },
      "source": [
        "## Import files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud9Q67WgKW91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96ebf20-cd1e-43b2-c039-ccf1dfce9a18"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('drive/My Drive/research/githubs/context_bert_model/JointBERT-master')\n",
        "# os.chdir('drive/My Drive/JointBERT-master') #set your own path here"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIgc60MfKne6"
      },
      "source": [
        "## Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqbe-BxIGp-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f211974b-cfa9-465c-94e3-f083b4ef1b0d"
      },
      "source": [
        "!pip install transformers==2.7.0\n",
        "!pip install seqeval==0.0.12\n",
        "!pip install pytorch-crf==0.7.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
            "\r\u001b[K     |▋                               | 10kB 7.6MB/s eta 0:00:01\r\u001b[K     |█▏                              | 20kB 12.4MB/s eta 0:00:01\r\u001b[K     |█▉                              | 30kB 16.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 40kB 19.4MB/s eta 0:00:01\r\u001b[K     |███                             | 51kB 15.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 61kB 17.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 71kB 12.8MB/s eta 0:00:01\r\u001b[K     |████▉                           | 81kB 11.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 102kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 112kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 122kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 133kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 143kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████                       | 153kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 163kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 174kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 184kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 194kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 204kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 215kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 225kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 235kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 245kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 256kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 266kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 276kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 286kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 296kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 307kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 317kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 327kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 337kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 348kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 358kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 368kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 378kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 389kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 399kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 409kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 419kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 430kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 440kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 450kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 460kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 471kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 481kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 491kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 501kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 512kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 522kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 532kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 542kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 552kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (0.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (2019.12.20)\n",
            "Collecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 29.6MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.7.0) (4.41.1)\n",
            "Collecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/20/88e9b0c843864737bd1e4139d397bcae1befacaff41b4ad1ae00013a6ef5/boto3-1.16.60-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 50.6MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.7.0) (1.24.3)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/43/4b4a1b26eb03a429a4c37ca7fdf369d938bd60018fc194e94b8379b0c77c/s3transfer-0.3.4-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.1MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.60\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/dc/171cf1c3e35e9b6da84e74e43fbdbc139ebe7181184f2da9cd628591a8a7/botocore-1.19.60-py2.py3-none-any.whl (7.2MB)\n",
            "\u001b[K     |████████████████████████████████| 7.2MB 46.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.60->boto3->transformers==2.7.0) (2.8.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=11b33269aed9a088d6f2342d252de5afd271ba5ce720498e4904a6f9107ec055\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.60 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tokenizers, sentencepiece, jmespath, botocore, s3transfer, boto3, sacremoses, transformers\n",
            "Successfully installed boto3-1.16.60 botocore-1.19.60 jmespath-0.10.0 s3transfer-0.3.4 sacremoses-0.0.43 sentencepiece-0.1.95 tokenizers-0.5.2 transformers-2.7.0\n",
            "Collecting seqeval==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.12) (1.19.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval==0.0.12) (2.4.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval==0.0.12) (2.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->Keras>=2.2.4->seqeval==0.0.12) (1.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=7739363f065cd2bba966a980fe68787658bd9eb88fde82210948e9c269b4ae9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-0.0.12\n",
            "Collecting pytorch-crf==0.7.2\n",
            "  Downloading https://files.pythonhosted.org/packages/96/7d/4c4688e26ea015fc118a0327e5726e6596836abce9182d3738be8ec2e32a/pytorch_crf-0.7.2-py3-none-any.whl\n",
            "Installing collected packages: pytorch-crf\n",
            "Successfully installed pytorch-crf-0.7.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rurIIdhvOAKo"
      },
      "source": [
        "# context model epoch 2 no separate with depth =2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAa5CVH6pvSK",
        "outputId": "2403e03b-ec14-4593-d493-7f10e0911a7c"
      },
      "source": [
        "!python3 main.py --task 45k_context_depth==2 \\\r\n",
        "--model_type bert \\\r\n",
        "--model_dir game_bert_model_save_dir1_11 \\\r\n",
        "--do_train \\\r\n",
        "--gradient_accumulation_steps 64 \\\r\n",
        "--do_eval \\\r\n",
        "--num_train_epochs 2 \\\r\n",
        "--logging_steps -1 \\\r\n",
        "--max_seq_len 100 \\\r\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-01-27 11:49:25.518209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "01/27/2021 11:49:28 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "01/27/2021 11:49:28 - INFO - data_loader -   Loading features from cached file ./data/cached_train_45k_context_depth==2_bert-base-uncased_100\n",
            "01/27/2021 11:49:31 - INFO - data_loader -   Loading features from cached file ./data/cached_dev_45k_context_depth==2_bert-base-uncased_100\n",
            "01/27/2021 11:49:32 - INFO - data_loader -   Loading features from cached file ./data/cached_test_45k_context_depth==2_bert-base-uncased_100\n",
            "01/27/2021 11:49:33 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "01/27/2021 11:49:33 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==2\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "01/27/2021 11:49:34 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "01/27/2021 11:49:37 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "01/27/2021 11:49:37 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "bert.embeddings.word_embeddings.weight\n",
            "bert.embeddings.position_embeddings.weight\n",
            "bert.embeddings.token_type_embeddings.weight\n",
            "bert.embeddings.LayerNorm.weight\n",
            "bert.embeddings.LayerNorm.bias\n",
            "bert.encoder.layer.0.attention.self.query.weight\n",
            "bert.encoder.layer.0.attention.self.query.bias\n",
            "bert.encoder.layer.0.attention.self.key.weight\n",
            "bert.encoder.layer.0.attention.self.key.bias\n",
            "bert.encoder.layer.0.attention.self.value.weight\n",
            "bert.encoder.layer.0.attention.self.value.bias\n",
            "bert.encoder.layer.0.attention.output.dense.weight\n",
            "bert.encoder.layer.0.attention.output.dense.bias\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.0.intermediate.dense.weight\n",
            "bert.encoder.layer.0.intermediate.dense.bias\n",
            "bert.encoder.layer.0.output.dense.weight\n",
            "bert.encoder.layer.0.output.dense.bias\n",
            "bert.encoder.layer.0.output.LayerNorm.weight\n",
            "bert.encoder.layer.0.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.attention.self.query.weight\n",
            "bert.encoder.layer.1.attention.self.query.bias\n",
            "bert.encoder.layer.1.attention.self.key.weight\n",
            "bert.encoder.layer.1.attention.self.key.bias\n",
            "bert.encoder.layer.1.attention.self.value.weight\n",
            "bert.encoder.layer.1.attention.self.value.bias\n",
            "bert.encoder.layer.1.attention.output.dense.weight\n",
            "bert.encoder.layer.1.attention.output.dense.bias\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.1.intermediate.dense.weight\n",
            "bert.encoder.layer.1.intermediate.dense.bias\n",
            "bert.encoder.layer.1.output.dense.weight\n",
            "bert.encoder.layer.1.output.dense.bias\n",
            "bert.encoder.layer.1.output.LayerNorm.weight\n",
            "bert.encoder.layer.1.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.attention.self.query.weight\n",
            "bert.encoder.layer.2.attention.self.query.bias\n",
            "bert.encoder.layer.2.attention.self.key.weight\n",
            "bert.encoder.layer.2.attention.self.key.bias\n",
            "bert.encoder.layer.2.attention.self.value.weight\n",
            "bert.encoder.layer.2.attention.self.value.bias\n",
            "bert.encoder.layer.2.attention.output.dense.weight\n",
            "bert.encoder.layer.2.attention.output.dense.bias\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.2.intermediate.dense.weight\n",
            "bert.encoder.layer.2.intermediate.dense.bias\n",
            "bert.encoder.layer.2.output.dense.weight\n",
            "bert.encoder.layer.2.output.dense.bias\n",
            "bert.encoder.layer.2.output.LayerNorm.weight\n",
            "bert.encoder.layer.2.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.attention.self.query.weight\n",
            "bert.encoder.layer.3.attention.self.query.bias\n",
            "bert.encoder.layer.3.attention.self.key.weight\n",
            "bert.encoder.layer.3.attention.self.key.bias\n",
            "bert.encoder.layer.3.attention.self.value.weight\n",
            "bert.encoder.layer.3.attention.self.value.bias\n",
            "bert.encoder.layer.3.attention.output.dense.weight\n",
            "bert.encoder.layer.3.attention.output.dense.bias\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.3.intermediate.dense.weight\n",
            "bert.encoder.layer.3.intermediate.dense.bias\n",
            "bert.encoder.layer.3.output.dense.weight\n",
            "bert.encoder.layer.3.output.dense.bias\n",
            "bert.encoder.layer.3.output.LayerNorm.weight\n",
            "bert.encoder.layer.3.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.attention.self.query.weight\n",
            "bert.encoder.layer.4.attention.self.query.bias\n",
            "bert.encoder.layer.4.attention.self.key.weight\n",
            "bert.encoder.layer.4.attention.self.key.bias\n",
            "bert.encoder.layer.4.attention.self.value.weight\n",
            "bert.encoder.layer.4.attention.self.value.bias\n",
            "bert.encoder.layer.4.attention.output.dense.weight\n",
            "bert.encoder.layer.4.attention.output.dense.bias\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.4.intermediate.dense.weight\n",
            "bert.encoder.layer.4.intermediate.dense.bias\n",
            "bert.encoder.layer.4.output.dense.weight\n",
            "bert.encoder.layer.4.output.dense.bias\n",
            "bert.encoder.layer.4.output.LayerNorm.weight\n",
            "bert.encoder.layer.4.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.attention.self.query.weight\n",
            "bert.encoder.layer.5.attention.self.query.bias\n",
            "bert.encoder.layer.5.attention.self.key.weight\n",
            "bert.encoder.layer.5.attention.self.key.bias\n",
            "bert.encoder.layer.5.attention.self.value.weight\n",
            "bert.encoder.layer.5.attention.self.value.bias\n",
            "bert.encoder.layer.5.attention.output.dense.weight\n",
            "bert.encoder.layer.5.attention.output.dense.bias\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.5.intermediate.dense.weight\n",
            "bert.encoder.layer.5.intermediate.dense.bias\n",
            "bert.encoder.layer.5.output.dense.weight\n",
            "bert.encoder.layer.5.output.dense.bias\n",
            "bert.encoder.layer.5.output.LayerNorm.weight\n",
            "bert.encoder.layer.5.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.attention.self.query.weight\n",
            "bert.encoder.layer.6.attention.self.query.bias\n",
            "bert.encoder.layer.6.attention.self.key.weight\n",
            "bert.encoder.layer.6.attention.self.key.bias\n",
            "bert.encoder.layer.6.attention.self.value.weight\n",
            "bert.encoder.layer.6.attention.self.value.bias\n",
            "bert.encoder.layer.6.attention.output.dense.weight\n",
            "bert.encoder.layer.6.attention.output.dense.bias\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.6.intermediate.dense.weight\n",
            "bert.encoder.layer.6.intermediate.dense.bias\n",
            "bert.encoder.layer.6.output.dense.weight\n",
            "bert.encoder.layer.6.output.dense.bias\n",
            "bert.encoder.layer.6.output.LayerNorm.weight\n",
            "bert.encoder.layer.6.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.attention.self.query.weight\n",
            "bert.encoder.layer.7.attention.self.query.bias\n",
            "bert.encoder.layer.7.attention.self.key.weight\n",
            "bert.encoder.layer.7.attention.self.key.bias\n",
            "bert.encoder.layer.7.attention.self.value.weight\n",
            "bert.encoder.layer.7.attention.self.value.bias\n",
            "bert.encoder.layer.7.attention.output.dense.weight\n",
            "bert.encoder.layer.7.attention.output.dense.bias\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.7.intermediate.dense.weight\n",
            "bert.encoder.layer.7.intermediate.dense.bias\n",
            "bert.encoder.layer.7.output.dense.weight\n",
            "bert.encoder.layer.7.output.dense.bias\n",
            "bert.encoder.layer.7.output.LayerNorm.weight\n",
            "bert.encoder.layer.7.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.attention.self.query.weight\n",
            "bert.encoder.layer.8.attention.self.query.bias\n",
            "bert.encoder.layer.8.attention.self.key.weight\n",
            "bert.encoder.layer.8.attention.self.key.bias\n",
            "bert.encoder.layer.8.attention.self.value.weight\n",
            "bert.encoder.layer.8.attention.self.value.bias\n",
            "bert.encoder.layer.8.attention.output.dense.weight\n",
            "bert.encoder.layer.8.attention.output.dense.bias\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.8.intermediate.dense.weight\n",
            "bert.encoder.layer.8.intermediate.dense.bias\n",
            "bert.encoder.layer.8.output.dense.weight\n",
            "bert.encoder.layer.8.output.dense.bias\n",
            "bert.encoder.layer.8.output.LayerNorm.weight\n",
            "bert.encoder.layer.8.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.attention.self.query.weight\n",
            "bert.encoder.layer.9.attention.self.query.bias\n",
            "bert.encoder.layer.9.attention.self.key.weight\n",
            "bert.encoder.layer.9.attention.self.key.bias\n",
            "bert.encoder.layer.9.attention.self.value.weight\n",
            "bert.encoder.layer.9.attention.self.value.bias\n",
            "bert.encoder.layer.9.attention.output.dense.weight\n",
            "bert.encoder.layer.9.attention.output.dense.bias\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.9.intermediate.dense.weight\n",
            "bert.encoder.layer.9.intermediate.dense.bias\n",
            "bert.encoder.layer.9.output.dense.weight\n",
            "bert.encoder.layer.9.output.dense.bias\n",
            "bert.encoder.layer.9.output.LayerNorm.weight\n",
            "bert.encoder.layer.9.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.attention.self.query.weight\n",
            "bert.encoder.layer.10.attention.self.query.bias\n",
            "bert.encoder.layer.10.attention.self.key.weight\n",
            "bert.encoder.layer.10.attention.self.key.bias\n",
            "bert.encoder.layer.10.attention.self.value.weight\n",
            "bert.encoder.layer.10.attention.self.value.bias\n",
            "bert.encoder.layer.10.attention.output.dense.weight\n",
            "bert.encoder.layer.10.attention.output.dense.bias\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.10.intermediate.dense.weight\n",
            "bert.encoder.layer.10.intermediate.dense.bias\n",
            "bert.encoder.layer.10.output.dense.weight\n",
            "bert.encoder.layer.10.output.dense.bias\n",
            "bert.encoder.layer.10.output.LayerNorm.weight\n",
            "bert.encoder.layer.10.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.attention.self.query.weight\n",
            "bert.encoder.layer.11.attention.self.query.bias\n",
            "bert.encoder.layer.11.attention.self.key.weight\n",
            "bert.encoder.layer.11.attention.self.key.bias\n",
            "bert.encoder.layer.11.attention.self.value.weight\n",
            "bert.encoder.layer.11.attention.self.value.bias\n",
            "bert.encoder.layer.11.attention.output.dense.weight\n",
            "bert.encoder.layer.11.attention.output.dense.bias\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
            "bert.encoder.layer.11.intermediate.dense.weight\n",
            "bert.encoder.layer.11.intermediate.dense.bias\n",
            "bert.encoder.layer.11.output.dense.weight\n",
            "bert.encoder.layer.11.output.dense.bias\n",
            "bert.encoder.layer.11.output.LayerNorm.weight\n",
            "bert.encoder.layer.11.output.LayerNorm.bias\n",
            "bert.pooler.dense.weight\n",
            "bert.pooler.dense.bias\n",
            "intent_classifier.linear.weight\n",
            "intent_classifier.linear.bias\n",
            "slot_classifier.linear.weight\n",
            "slot_classifier.linear.bias\n",
            "context_lstm.weight_ih_l0\n",
            "context_lstm.weight_hh_l0\n",
            "context_lstm.bias_ih_l0\n",
            "context_lstm.bias_hh_l0\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 76, in <module>\n",
            "    main(args)\n",
            "  File \"main.py\", line 20, in main\n",
            "    trainer.train()\n",
            "  File \"/content/drive/My Drive/research/githubs/game_bert_model/JointBERT-master/trainer.py\", line 81, in train\n",
            "    print(1/0)\n",
            "ZeroDivisionError: division by zero\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWEDS16gYN1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889b3aee-3af8-49f1-d1c1-8f2127cde0be"
      },
      "source": [
        "!python3 main.py --task 45k_context_depth==2 \\\n",
        "--model_type bert \\\n",
        "--model_dir game_bert_model_save_dir1 \\\n",
        "--do_train \\\n",
        "--gradient_accumulation_steps 64 \\\n",
        "--do_eval \\\n",
        "--num_train_epochs 2 \\\n",
        "--logging_steps -1 \\\n",
        "--max_seq_len 100 \\\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-11 09:14:52.162938: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/11/2020 09:14:59 - INFO - filelock -   Lock 140447018798944 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "12/11/2020 09:14:59 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpskie9ebg\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 705kB/s]\n",
            "12/11/2020 09:15:00 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/11/2020 09:15:00 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/11/2020 09:15:00 - INFO - filelock -   Lock 140447018798944 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
            "12/11/2020 09:15:00 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/11/2020 09:15:01 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/11/2020 09:15:01 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==2/train\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   guid: train-0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   tokens: [CLS] wow [SEP]\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   input_ids: 101 10166 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   guid: train-1\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   tokens: [CLS] w ##tf [SEP]\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   input_ids: 101 1059 24475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   guid: train-2\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   tokens: [CLS] w ##pe w ##pe [SEP]\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   input_ids: 101 1059 5051 1059 5051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   slot_labels: 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   guid: train-3\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   tokens: [CLS] ha ##ha ##ha [SEP]\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   input_ids: 101 5292 3270 3270 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   attention_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   guid: train-4\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   tokens: [CLS] w ##tf [SEP]\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   input_ids: 101 1059 24475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:04 - INFO - data_loader -   Writing example 100 of 26921\n",
            "12/11/2020 09:15:06 - INFO - data_loader -   Writing example 5100 of 26921\n",
            "12/11/2020 09:15:09 - INFO - data_loader -   Writing example 10100 of 26921\n",
            "12/11/2020 09:15:11 - INFO - data_loader -   Writing example 15100 of 26921\n",
            "12/11/2020 09:15:13 - INFO - data_loader -   Writing example 20100 of 26921\n",
            "12/11/2020 09:15:16 - INFO - data_loader -   Writing example 25100 of 26921\n",
            "12/11/2020 09:15:17 - INFO - data_loader -   Saving features into cached file ./data/cached_train_45k_context_depth==2_bert-base-uncased_100\n",
            "12/11/2020 09:15:24 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/11/2020 09:15:24 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==2/dev\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   guid: dev-0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   guid: dev-1\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   guid: dev-2\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   tokens: [CLS] g ##g [ sep ##a ] nice late game [SEP]\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   input_ids: 101 1043 2290 1031 19802 2050 1033 3835 2397 2208 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   slot_labels: 0 5 0 8 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   guid: dev-3\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   tokens: [CLS] fu ##k [SEP]\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   input_ids: 101 11865 2243 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   intent_label: 2 (id = 2)\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   guid: dev-4\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   tokens: [CLS] ; ) [SEP]\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   input_ids: 101 1025 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:26 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/11/2020 09:15:29 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/11/2020 09:15:30 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_45k_context_depth==2_bert-base-uncased_100\n",
            "12/11/2020 09:15:33 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/11/2020 09:15:33 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==2/test\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   guid: test-0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   tokens: [CLS] def ##f [SEP]\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   input_ids: 101 13366 2546 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   guid: test-1\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   tokens: [CLS] su ##p [SEP]\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   input_ids: 101 10514 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   guid: test-2\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   tokens: [CLS] like i sad [ sep ##a ] buy back to dead [SEP]\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   input_ids: 101 2066 1045 6517 1031 19802 2050 1033 4965 2067 2000 2757 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   slot_labels: 0 2 3 2 8 0 0 0 2 5 2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   guid: test-3\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   tokens: [CLS] hi aba [SEP]\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   input_ids: 101 7632 19557 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   *** Example ***\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   guid: test-4\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   tokens: [CLS] kiss u [SEP]\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   input_ids: 101 3610 1057 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   slot_labels: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/11/2020 09:15:35 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/11/2020 09:15:36 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/11/2020 09:15:37 - INFO - data_loader -   Saving features into cached file ./data/cached_test_45k_context_depth==2_bert-base-uncased_100\n",
            "12/11/2020 09:15:39 - INFO - filelock -   Lock 140447018798720 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "12/11/2020 09:15:39 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpr3qyr2l4\n",
            "Downloading: 100% 433/433 [00:00<00:00, 256kB/s]\n",
            "12/11/2020 09:15:39 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/11/2020 09:15:39 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/11/2020 09:15:39 - INFO - filelock -   Lock 140447018798720 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "12/11/2020 09:15:39 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/11/2020 09:15:39 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==2\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/11/2020 09:15:40 - INFO - filelock -   Lock 140446872011888 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "12/11/2020 09:15:40 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpx2oqanwv\n",
            "Downloading: 100% 440M/440M [00:15<00:00, 28.9MB/s]\n",
            "12/11/2020 09:15:55 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/11/2020 09:15:55 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/11/2020 09:15:55 - INFO - filelock -   Lock 140446872011888 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "12/11/2020 09:15:55 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/11/2020 09:15:59 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "12/11/2020 09:15:59 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "12/11/2020 09:16:08 - INFO - trainer -   ***** Running training *****\n",
            "12/11/2020 09:16:08 - INFO - trainer -     Num examples = 26921\n",
            "12/11/2020 09:16:08 - INFO - trainer -     Num Epochs = 2\n",
            "12/11/2020 09:16:08 - INFO - trainer -     Total train batch size = 1\n",
            "12/11/2020 09:16:08 - INFO - trainer -     Gradient Accumulation steps = 64\n",
            "12/11/2020 09:16:08 - INFO - trainer -     Total optimization steps = 840\n",
            "12/11/2020 09:16:08 - INFO - trainer -     Logging steps = -1\n",
            "12/11/2020 09:16:08 - INFO - trainer -     Save steps = 200\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/26921 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   8% 2086/26921 [03:20<39:41, 10.43it/s]\u001b[A\n",
            "Iteration:   8% 2086/26921 [03:40<39:41, 10.43it/s]\u001b[A\n",
            "Iteration:  16% 4191/26921 [06:40<36:13, 10.46it/s]\u001b[A\n",
            "Iteration:  16% 4191/26921 [07:00<36:13, 10.46it/s]\u001b[A\n",
            "Iteration:  23% 6293/26921 [10:00<32:49, 10.47it/s]\u001b[A\n",
            "Iteration:  23% 6293/26921 [10:20<32:49, 10.47it/s]\u001b[A\n",
            "Iteration:  31% 8406/26921 [13:20<29:23, 10.50it/s]\u001b[A\n",
            "Iteration:  31% 8406/26921 [13:40<29:23, 10.50it/s]\u001b[A\n",
            "Iteration:  39% 10497/26921 [16:40<26:06, 10.49it/s]\u001b[A\n",
            "Iteration:  39% 10497/26921 [17:00<26:06, 10.49it/s]\u001b[A\n",
            "Iteration:  47% 12597/26921 [20:00<22:45, 10.49it/s]\u001b[A12/11/2020 09:36:27 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "\n",
            "Iteration:  47% 12597/26921 [20:20<22:45, 10.49it/s]\u001b[A12/11/2020 09:36:30 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/11/2020 09:36:30 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  54% 14646/26921 [23:20<19:38, 10.41it/s]\u001b[A\n",
            "Iteration:  54% 14646/26921 [23:40<19:38, 10.41it/s]\u001b[A\n",
            "Iteration:  62% 16724/26921 [26:40<16:19, 10.41it/s]\u001b[A\n",
            "Iteration:  62% 16724/26921 [27:00<16:19, 10.41it/s]\u001b[A\n",
            "Iteration:  70% 18797/26921 [30:00<13:01, 10.39it/s]\u001b[A\n",
            "Iteration:  70% 18797/26921 [30:20<13:01, 10.39it/s]\u001b[A\n",
            "Iteration:  78% 20887/26921 [33:20<09:39, 10.41it/s]\u001b[A\n",
            "Iteration:  78% 20887/26921 [33:40<09:39, 10.41it/s]\u001b[A\n",
            "Iteration:  85% 22986/26921 [36:40<06:17, 10.43it/s]\u001b[A\n",
            "Iteration:  85% 22986/26921 [37:00<06:17, 10.43it/s]\u001b[A\n",
            "Iteration:  93% 25083/26921 [40:00<02:55, 10.45it/s]\u001b[A\n",
            "Iteration:  93% 25083/26921 [40:20<02:55, 10.45it/s]\u001b[A12/11/2020 09:56:59 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/11/2020 09:57:01 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/11/2020 09:57:01 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "Iteration: 100% 26921/26921 [43:00<00:00, 10.43it/s]\n",
            "Epoch:  50% 1/2 [43:00<43:00, 2580.28s/it]\n",
            "Iteration:   0% 0/26921 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   8% 2072/26921 [03:20<39:59, 10.36it/s]\u001b[A\n",
            "Iteration:   8% 2072/26921 [03:39<39:59, 10.36it/s]\u001b[A\n",
            "Iteration:  15% 4162/26921 [06:40<36:31, 10.38it/s]\u001b[A\n",
            "Iteration:  15% 4162/26921 [06:59<36:31, 10.38it/s]\u001b[A\n",
            "Iteration:  23% 6270/26921 [10:00<33:00, 10.43it/s]\u001b[A\n",
            "Iteration:  23% 6270/26921 [10:19<33:00, 10.43it/s]\u001b[A\n",
            "Iteration:  31% 8333/26921 [13:20<29:48, 10.39it/s]\u001b[A\n",
            "Iteration:  31% 8333/26921 [13:39<29:48, 10.39it/s]\u001b[A\n",
            "Iteration:  39% 10425/26921 [16:40<26:24, 10.41it/s]\u001b[A\n",
            "Iteration:  39% 10425/26921 [16:59<26:24, 10.41it/s]\u001b[A12/11/2020 10:17:34 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/11/2020 10:17:37 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/11/2020 10:17:37 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  46% 12459/26921 [20:00<23:18, 10.34it/s]\u001b[A\n",
            "Iteration:  46% 12459/26921 [20:19<23:18, 10.34it/s]\u001b[A\n",
            "Iteration:  54% 14515/26921 [23:20<20:02, 10.32it/s]\u001b[A\n",
            "Iteration:  54% 14515/26921 [23:39<20:02, 10.32it/s]\u001b[A\n",
            "Iteration:  62% 16574/26921 [26:40<16:43, 10.31it/s]\u001b[A\n",
            "Iteration:  62% 16574/26921 [26:59<16:43, 10.31it/s]\u001b[A\n",
            "Iteration:  69% 18698/26921 [30:00<13:10, 10.40it/s]\u001b[A\n",
            "Iteration:  69% 18698/26921 [30:19<13:10, 10.40it/s]\u001b[A\n",
            "Iteration:  77% 20770/26921 [33:20<09:52, 10.39it/s]\u001b[A\n",
            "Iteration:  77% 20770/26921 [33:39<09:52, 10.39it/s]\u001b[A\n",
            "Iteration:  85% 22825/26921 [36:40<06:35, 10.35it/s]\u001b[A\n",
            "Iteration:  85% 22825/26921 [36:59<06:35, 10.35it/s]\u001b[A12/11/2020 10:38:14 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/11/2020 10:38:16 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/11/2020 10:38:16 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  92% 24853/26921 [40:00<03:21, 10.29it/s]\u001b[A\n",
            "Iteration: 100% 26921/26921 [43:18<00:00, 10.36it/s]\n",
            "Epoch: 100% 2/2 [1:26:18<00:00, 2589.38s/it]\n",
            "12/11/2020 10:42:27 - INFO - transformers.configuration_utils -   loading configuration file game_bert_model_save_dir1/config.json\n",
            "12/11/2020 10:42:27 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==2\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/11/2020 10:42:27 - INFO - transformers.modeling_utils -   loading weights file game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/11/2020 10:42:31 - INFO - trainer -   ***** Model Loaded *****\n",
            "12/11/2020 10:42:31 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "12/11/2020 10:42:31 - INFO - trainer -     Num examples = 8974\n",
            "12/11/2020 10:42:31 - INFO - trainer -     Batch size = 1\n",
            "Evaluating: 100% 8974/8974 [03:25<00:00, 43.64it/s]\n",
            "12/11/2020 10:45:57 - INFO - trainer -   ***** Eval results *****\n",
            "12/11/2020 10:45:57 - INFO - trainer -     intent_acc = 0.9204368174726989\n",
            "12/11/2020 10:45:57 - INFO - trainer -     loss = 0.2777486800157295\n",
            "12/11/2020 10:45:57 - INFO - trainer -     sementic_frame_acc = 0.22698907956318254\n",
            "12/11/2020 10:45:57 - INFO - trainer -     slot_f1 = 0.06885721188692921\n",
            "12/11/2020 10:45:57 - INFO - trainer -     slot_precision = 0.08064516129032258\n",
            "12/11/2020 10:45:57 - INFO - trainer -     slot_recall = 0.060075885328836426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8D8EcahvN4RV"
      },
      "source": [
        "# context model epoch 2 no separate with depth =4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2-BulxYQUME",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "764cc1ad-82ef-4d30-8835-2cfbbb1cbfab"
      },
      "source": [
        "!python3 main.py --task 45k_context_depth==4 \\\n",
        "--model_type bert \\\n",
        "--model_dir game_bert_model_save_dir1 \\\n",
        "--do_train \\\n",
        "--gradient_accumulation_steps 64 \\\n",
        "--do_eval \\\n",
        "--num_train_epochs 2 \\\n",
        "--logging_steps -1 \\\n",
        "--max_seq_len 100 \\\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-12 02:12:39.895280: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/12/2020 02:12:42 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/12/2020 02:12:43 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 02:12:43 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==4/train\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   guid: train-0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   tokens: [CLS] wow [SEP]\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   input_ids: 101 10166 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   guid: train-1\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   tokens: [CLS] w ##tf [SEP]\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   input_ids: 101 1059 24475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   guid: train-2\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   tokens: [CLS] w ##pe w ##pe [SEP]\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   input_ids: 101 1059 5051 1059 5051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   slot_labels: 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   guid: train-3\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   tokens: [CLS] ha ##ha ##ha [SEP]\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   input_ids: 101 5292 3270 3270 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   attention_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   guid: train-4\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   tokens: [CLS] w ##tf [SEP]\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   input_ids: 101 1059 24475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:12:45 - INFO - data_loader -   Writing example 100 of 26921\n",
            "12/12/2020 02:12:48 - INFO - data_loader -   Writing example 5100 of 26921\n",
            "12/12/2020 02:12:51 - INFO - data_loader -   Writing example 10100 of 26921\n",
            "12/12/2020 02:12:53 - INFO - data_loader -   Writing example 15100 of 26921\n",
            "12/12/2020 02:12:56 - INFO - data_loader -   Writing example 20100 of 26921\n",
            "12/12/2020 02:12:59 - INFO - data_loader -   Writing example 25100 of 26921\n",
            "12/12/2020 02:13:00 - INFO - data_loader -   Saving features into cached file ./data/cached_train_45k_context_depth==4_bert-base-uncased_100\n",
            "12/12/2020 02:13:09 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 02:13:09 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==4/dev\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   guid: dev-0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   tokens: [CLS] def ##f [SEP]\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   input_ids: 101 13366 2546 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   guid: dev-1\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   tokens: [CLS] su ##p [SEP]\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   input_ids: 101 10514 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   guid: dev-2\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   tokens: [CLS] like i sad [ sep ##a ] buy back to dead [SEP]\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   input_ids: 101 2066 1045 6517 1031 19802 2050 1033 4965 2067 2000 2757 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   slot_labels: 0 2 3 2 8 0 0 0 2 5 2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   guid: dev-3\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   tokens: [CLS] hi aba [SEP]\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   input_ids: 101 7632 19557 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   guid: dev-4\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   tokens: [CLS] kiss u [SEP]\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   input_ids: 101 3610 1057 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   slot_labels: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:11 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/12/2020 02:13:12 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/12/2020 02:13:13 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_45k_context_depth==4_bert-base-uncased_100\n",
            "12/12/2020 02:13:15 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 02:13:15 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==4/test\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   guid: test-0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   tokens: [CLS] def ##f [SEP]\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   input_ids: 101 13366 2546 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   guid: test-1\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   tokens: [CLS] su ##p [SEP]\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   input_ids: 101 10514 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   guid: test-2\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   tokens: [CLS] like i sad [ sep ##a ] buy back to dead [SEP]\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   input_ids: 101 2066 1045 6517 1031 19802 2050 1033 4965 2067 2000 2757 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   slot_labels: 0 2 3 2 8 0 0 0 2 5 2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   guid: test-3\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   tokens: [CLS] hi aba [SEP]\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   input_ids: 101 7632 19557 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   guid: test-4\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   tokens: [CLS] kiss u [SEP]\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   input_ids: 101 3610 1057 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   slot_labels: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 02:13:16 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/12/2020 02:13:17 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/12/2020 02:13:18 - INFO - data_loader -   Saving features into cached file ./data/cached_test_45k_context_depth==4_bert-base-uncased_100\n",
            "12/12/2020 02:13:20 - INFO - filelock -   Lock 139922700675784 acquired on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "12/12/2020 02:13:20 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpwo7phvqu\n",
            "Downloading: 100% 433/433 [00:00<00:00, 361kB/s]\n",
            "12/12/2020 02:13:20 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json in cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/12/2020 02:13:20 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/12/2020 02:13:20 - INFO - filelock -   Lock 139922700675784 released on /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517.lock\n",
            "12/12/2020 02:13:20 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/12/2020 02:13:20 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==4\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/12/2020 02:13:21 - INFO - filelock -   Lock 139922842673104 acquired on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "12/12/2020 02:13:21 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp64yoa1or\n",
            "Downloading: 100% 440M/440M [00:14<00:00, 29.7MB/s]\n",
            "12/12/2020 02:13:36 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/12/2020 02:13:36 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/12/2020 02:13:36 - INFO - filelock -   Lock 139922842673104 released on /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "12/12/2020 02:13:36 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/12/2020 02:13:39 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "12/12/2020 02:13:39 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "12/12/2020 02:13:49 - INFO - trainer -   ***** Running training *****\n",
            "12/12/2020 02:13:49 - INFO - trainer -     Num examples = 26921\n",
            "12/12/2020 02:13:49 - INFO - trainer -     Num Epochs = 2\n",
            "12/12/2020 02:13:49 - INFO - trainer -     Total train batch size = 1\n",
            "12/12/2020 02:13:49 - INFO - trainer -     Gradient Accumulation steps = 64\n",
            "12/12/2020 02:13:49 - INFO - trainer -     Total optimization steps = 840\n",
            "12/12/2020 02:13:49 - INFO - trainer -     Logging steps = -1\n",
            "12/12/2020 02:13:49 - INFO - trainer -     Save steps = 200\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/26921 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   7% 1882/26921 [03:20<44:21,  9.41it/s]\u001b[A\n",
            "Iteration:   7% 1882/26921 [03:40<44:21,  9.41it/s]\u001b[A\n",
            "Iteration:  14% 3760/26921 [06:40<41:03,  9.40it/s]\u001b[A\n",
            "Iteration:  14% 3760/26921 [07:00<41:03,  9.40it/s]\u001b[A\n",
            "Iteration:  21% 5681/26921 [10:00<37:25,  9.46it/s]\u001b[A\n",
            "Iteration:  21% 5681/26921 [10:20<37:25,  9.46it/s]\u001b[A\n",
            "Iteration:  28% 7540/26921 [13:20<34:19,  9.41it/s]\u001b[A\n",
            "Iteration:  28% 7540/26921 [13:40<34:19,  9.41it/s]\u001b[A\n",
            "Iteration:  35% 9472/26921 [16:40<30:40,  9.48it/s]\u001b[A\n",
            "Iteration:  35% 9472/26921 [17:00<30:40,  9.48it/s]\u001b[A\n",
            "Iteration:  42% 11378/26921 [20:00<27:16,  9.50it/s]\u001b[A\n",
            "Iteration:  42% 11378/26921 [20:20<27:16,  9.50it/s]\u001b[A12/12/2020 02:36:15 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 02:36:23 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 02:36:23 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  49% 13232/26921 [23:20<24:12,  9.43it/s]\u001b[A\n",
            "Iteration:  49% 13232/26921 [23:40<24:12,  9.43it/s]\u001b[A\n",
            "Iteration:  56% 15129/26921 [26:40<20:48,  9.44it/s]\u001b[A\n",
            "Iteration:  56% 15129/26921 [27:00<20:48,  9.44it/s]\u001b[A\n",
            "Iteration:  63% 17008/26921 [30:00<17:31,  9.43it/s]\u001b[A\n",
            "Iteration:  63% 17008/26921 [30:20<17:31,  9.43it/s]\u001b[A\n",
            "Iteration:  70% 18899/26921 [33:20<14:10,  9.43it/s]\u001b[A\n",
            "Iteration:  70% 18899/26921 [33:40<14:10,  9.43it/s]\u001b[A\n",
            "Iteration:  77% 20807/26921 [36:40<10:45,  9.47it/s]\u001b[A\n",
            "Iteration:  77% 20807/26921 [37:00<10:45,  9.47it/s]\u001b[A\n",
            "Iteration:  84% 22696/26921 [40:00<07:26,  9.46it/s]\u001b[A\n",
            "Iteration:  84% 22696/26921 [40:20<07:26,  9.46it/s]\u001b[A\n",
            "Iteration:  91% 24613/26921 [43:20<04:03,  9.50it/s]\u001b[A\n",
            "Iteration:  91% 24613/26921 [43:40<04:03,  9.50it/s]\u001b[A12/12/2020 02:58:54 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 02:58:56 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 02:58:56 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  98% 26482/26921 [46:40<00:46,  9.45it/s]\u001b[A\n",
            "Iteration: 100% 26921/26921 [47:28<00:00,  9.45it/s]\n",
            "Epoch:  50% 1/2 [47:28<47:28, 2848.59s/it]\n",
            "Iteration:   0% 0/26921 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   7% 1854/26921 [03:20<45:04,  9.27it/s]\u001b[A\n",
            "Iteration:   7% 1854/26921 [03:31<45:04,  9.27it/s]\u001b[A\n",
            "Iteration:  14% 3743/26921 [06:40<41:26,  9.32it/s]\u001b[A\n",
            "Iteration:  14% 3743/26921 [06:51<41:26,  9.32it/s]\u001b[A\n",
            "Iteration:  21% 5644/26921 [10:00<37:49,  9.38it/s]\u001b[A\n",
            "Iteration:  21% 5644/26921 [10:11<37:49,  9.38it/s]\u001b[A\n",
            "Iteration:  28% 7549/26921 [13:20<34:16,  9.42it/s]\u001b[A\n",
            "Iteration:  28% 7549/26921 [13:31<34:16,  9.42it/s]\u001b[A\n",
            "Iteration:  35% 9466/26921 [16:40<30:43,  9.47it/s]\u001b[A\n",
            "Iteration:  35% 9466/26921 [16:51<30:43,  9.47it/s]\u001b[A\n",
            "Iteration:  42% 11369/26921 [20:00<27:20,  9.48it/s]\u001b[A\n",
            "Iteration:  42% 11369/26921 [20:11<27:20,  9.48it/s]\u001b[A12/12/2020 03:21:33 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 03:21:35 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 03:21:35 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  49% 13215/26921 [23:20<24:17,  9.40it/s]\u001b[A\n",
            "Iteration:  49% 13215/26921 [23:31<24:17,  9.40it/s]\u001b[A\n",
            "Iteration:  56% 15093/26921 [26:40<20:58,  9.40it/s]\u001b[A\n",
            "Iteration:  56% 15093/26921 [26:51<20:58,  9.40it/s]\u001b[A\n",
            "Iteration:  63% 16986/26921 [30:00<17:34,  9.42it/s]\u001b[A\n",
            "Iteration:  63% 16986/26921 [30:11<17:34,  9.42it/s]\u001b[A\n",
            "Iteration:  70% 18920/26921 [33:20<14:03,  9.49it/s]\u001b[A\n",
            "Iteration:  70% 18920/26921 [33:31<14:03,  9.49it/s]\u001b[A\n",
            "Iteration:  77% 20789/26921 [36:40<10:49,  9.45it/s]\u001b[A\n",
            "Iteration:  77% 20789/26921 [36:51<10:49,  9.45it/s]\u001b[A\n",
            "Iteration:  84% 22607/26921 [40:00<07:42,  9.34it/s]\u001b[A\n",
            "Iteration:  84% 22607/26921 [40:11<07:42,  9.34it/s]\u001b[A12/12/2020 03:44:20 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 03:44:22 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 03:44:22 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  91% 24454/26921 [43:20<04:25,  9.31it/s]\u001b[A\n",
            "Iteration:  91% 24454/26921 [43:31<04:25,  9.31it/s]\u001b[A\n",
            "Iteration:  98% 26378/26921 [46:40<00:57,  9.40it/s]\u001b[A\n",
            "Iteration: 100% 26921/26921 [47:35<00:00,  9.43it/s]\n",
            "Epoch: 100% 2/2 [1:35:04<00:00, 2852.22s/it]\n",
            "12/12/2020 03:48:53 - INFO - transformers.configuration_utils -   loading configuration file game_bert_model_save_dir1/config.json\n",
            "12/12/2020 03:48:53 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==4\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/12/2020 03:48:53 - INFO - transformers.modeling_utils -   loading weights file game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 03:48:56 - INFO - trainer -   ***** Model Loaded *****\n",
            "12/12/2020 03:48:56 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "12/12/2020 03:48:56 - INFO - trainer -     Num examples = 8974\n",
            "12/12/2020 03:48:56 - INFO - trainer -     Batch size = 1\n",
            "Evaluating: 100% 8974/8974 [02:38<00:00, 56.65it/s]\n",
            "12/12/2020 03:51:35 - INFO - trainer -   ***** Eval results *****\n",
            "12/12/2020 03:51:35 - INFO - trainer -     intent_acc = 0.920771116558948\n",
            "12/12/2020 03:51:35 - INFO - trainer -     loss = 0.2759581747475369\n",
            "12/12/2020 03:51:35 - INFO - trainer -     sementic_frame_acc = 0.2029195453532427\n",
            "12/12/2020 03:51:35 - INFO - trainer -     slot_f1 = 0.03039197473527773\n",
            "12/12/2020 03:51:35 - INFO - trainer -     slot_precision = 0.03224789087755263\n",
            "12/12/2020 03:51:35 - INFO - trainer -     slot_recall = 0.0287380550871276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAjRuceCt2nc"
      },
      "source": [
        "# context model epoch 2 with depth 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jjQ6rqzuTSA",
        "outputId": "79d4154f-7fa7-4efc-df1b-0c43be2cfec5"
      },
      "source": [
        "!python3 main.py --task 45k_context_depth==6 \\\n",
        "--model_type bert \\\n",
        "--model_dir game_bert_model_save_dir1 \\\n",
        "--do_train \\\n",
        "--gradient_accumulation_steps 64 \\\n",
        "--do_eval \\\n",
        "--num_train_epochs 2 \\\n",
        "--logging_steps -1 \\\n",
        "--max_seq_len 100 \\\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-12 03:51:40.516214: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/12/2020 03:51:42 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/12/2020 03:51:43 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 03:51:43 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==6/train\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   guid: train-0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   tokens: [CLS] wow [SEP]\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   input_ids: 101 10166 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   guid: train-1\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   tokens: [CLS] w ##tf [SEP]\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   input_ids: 101 1059 24475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   guid: train-2\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   tokens: [CLS] w ##pe w ##pe [SEP]\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   input_ids: 101 1059 5051 1059 5051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   slot_labels: 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   guid: train-3\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   tokens: [CLS] ha ##ha ##ha [SEP]\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   input_ids: 101 5292 3270 3270 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   attention_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   guid: train-4\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   tokens: [CLS] w ##tf [SEP]\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   input_ids: 101 1059 24475 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:51:45 - INFO - data_loader -   Writing example 100 of 26921\n",
            "12/12/2020 03:51:48 - INFO - data_loader -   Writing example 5100 of 26921\n",
            "12/12/2020 03:51:51 - INFO - data_loader -   Writing example 10100 of 26921\n",
            "12/12/2020 03:51:54 - INFO - data_loader -   Writing example 15100 of 26921\n",
            "12/12/2020 03:51:57 - INFO - data_loader -   Writing example 20100 of 26921\n",
            "12/12/2020 03:52:00 - INFO - data_loader -   Writing example 25100 of 26921\n",
            "12/12/2020 03:52:01 - INFO - data_loader -   Saving features into cached file ./data/cached_train_45k_context_depth==6_bert-base-uncased_100\n",
            "12/12/2020 03:52:12 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 03:52:12 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==6/dev\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   guid: dev-0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   guid: dev-1\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   guid: dev-2\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   tokens: [CLS] g ##g [ sep ##a ] nice late game [SEP]\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   input_ids: 101 1043 2290 1031 19802 2050 1033 3835 2397 2208 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   slot_labels: 0 5 0 8 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   guid: dev-3\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   tokens: [CLS] fu ##k [SEP]\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   input_ids: 101 11865 2243 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   intent_label: 2 (id = 2)\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   guid: dev-4\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   tokens: [CLS] ; ) [SEP]\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   input_ids: 101 1025 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:14 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/12/2020 03:52:17 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/12/2020 03:52:19 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_45k_context_depth==6_bert-base-uncased_100\n",
            "12/12/2020 03:52:23 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 03:52:23 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==6/test\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   guid: test-0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   tokens: [CLS] def ##f [SEP]\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   input_ids: 101 13366 2546 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   guid: test-1\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   tokens: [CLS] su ##p [SEP]\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   input_ids: 101 10514 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   guid: test-2\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   tokens: [CLS] like i sad [ sep ##a ] buy back to dead [SEP]\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   input_ids: 101 2066 1045 6517 1031 19802 2050 1033 4965 2067 2000 2757 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   slot_labels: 0 2 3 2 8 0 0 0 2 5 2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   guid: test-3\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   tokens: [CLS] hi aba [SEP]\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   input_ids: 101 7632 19557 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   guid: test-4\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   tokens: [CLS] kiss u [SEP]\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   input_ids: 101 3610 1057 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   slot_labels: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 03:52:25 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/12/2020 03:52:26 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/12/2020 03:52:27 - INFO - data_loader -   Saving features into cached file ./data/cached_test_45k_context_depth==6_bert-base-uncased_100\n",
            "12/12/2020 03:52:28 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/12/2020 03:52:28 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==6\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/12/2020 03:52:29 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/12/2020 03:52:31 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "12/12/2020 03:52:31 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "12/12/2020 03:52:37 - INFO - trainer -   ***** Running training *****\n",
            "12/12/2020 03:52:37 - INFO - trainer -     Num examples = 26921\n",
            "12/12/2020 03:52:37 - INFO - trainer -     Num Epochs = 2\n",
            "12/12/2020 03:52:37 - INFO - trainer -     Total train batch size = 1\n",
            "12/12/2020 03:52:37 - INFO - trainer -     Gradient Accumulation steps = 64\n",
            "12/12/2020 03:52:37 - INFO - trainer -     Total optimization steps = 840\n",
            "12/12/2020 03:52:37 - INFO - trainer -     Logging steps = -1\n",
            "12/12/2020 03:52:37 - INFO - trainer -     Save steps = 200\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/26921 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   6% 1640/26921 [03:20<51:24,  8.20it/s]\u001b[A\n",
            "Iteration:   6% 1640/26921 [03:40<51:24,  8.20it/s]\u001b[A\n",
            "Iteration:  12% 3181/26921 [06:40<49:12,  8.04it/s]\u001b[A\n",
            "Iteration:  12% 3181/26921 [07:00<49:12,  8.04it/s]\u001b[A\n",
            "Iteration:  18% 4737/26921 [10:00<46:27,  7.96it/s]\u001b[A\n",
            "Iteration:  18% 4737/26921 [10:20<46:27,  7.96it/s]\u001b[A\n",
            "Iteration:  23% 6318/26921 [13:20<43:14,  7.94it/s]\u001b[A\n",
            "Iteration:  23% 6318/26921 [13:40<43:14,  7.94it/s]\u001b[A\n",
            "Iteration:  29% 7871/26921 [16:40<40:15,  7.89it/s]\u001b[A\n",
            "Iteration:  29% 7871/26921 [17:00<40:15,  7.89it/s]\u001b[A\n",
            "Iteration:  35% 9457/26921 [20:00<36:50,  7.90it/s]\u001b[A\n",
            "Iteration:  35% 9457/26921 [20:20<36:50,  7.90it/s]\u001b[A\n",
            "Iteration:  41% 11002/26921 [23:20<33:49,  7.84it/s]\u001b[A\n",
            "Iteration:  41% 11002/26921 [23:40<33:49,  7.84it/s]\u001b[A\n",
            "Iteration:  47% 12593/26921 [26:40<30:19,  7.88it/s]\u001b[A\n",
            "Iteration:  47% 12593/26921 [27:00<30:19,  7.88it/s]\u001b[A12/12/2020 04:19:42 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 04:19:44 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 04:19:44 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  53% 14143/26921 [30:00<27:10,  7.84it/s]\u001b[A\n",
            "Iteration:  53% 14143/26921 [30:20<27:10,  7.84it/s]\u001b[A\n",
            "Iteration:  58% 15697/26921 [33:20<23:56,  7.82it/s]\u001b[A\n",
            "Iteration:  58% 15697/26921 [33:40<23:56,  7.82it/s]\u001b[A\n",
            "Iteration:  64% 17255/26921 [36:41<20:38,  7.81it/s]\u001b[A\n",
            "Iteration:  64% 17255/26921 [37:00<20:38,  7.81it/s]\u001b[A\n",
            "Iteration:  70% 18786/26921 [40:01<17:28,  7.76it/s]\u001b[A\n",
            "Iteration:  70% 18786/26921 [40:20<17:28,  7.76it/s]\u001b[A\n",
            "Iteration:  76% 20336/26921 [43:21<14:09,  7.75it/s]\u001b[A\n",
            "Iteration:  76% 20336/26921 [43:40<14:09,  7.75it/s]\u001b[A\n",
            "Iteration:  81% 21888/26921 [46:41<10:49,  7.75it/s]\u001b[A\n",
            "Iteration:  81% 21888/26921 [47:00<10:49,  7.75it/s]\u001b[A\n",
            "Iteration:  87% 23423/26921 [50:01<07:32,  7.73it/s]\u001b[A\n",
            "Iteration:  87% 23423/26921 [50:20<07:32,  7.73it/s]\u001b[A\n",
            "Iteration:  93% 24988/26921 [53:21<04:09,  7.76it/s]\u001b[A\n",
            "Iteration:  93% 24988/26921 [53:40<04:09,  7.76it/s]\u001b[A12/12/2020 04:47:18 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 04:47:20 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 04:47:20 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  98% 26513/26921 [56:41<00:52,  7.72it/s]\u001b[A\n",
            "Iteration: 100% 26921/26921 [57:35<00:00,  7.79it/s]\n",
            "Epoch:  50% 1/2 [57:35<57:35, 3455.97s/it]\n",
            "Iteration:   0% 0/26921 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   6% 1536/26921 [03:20<55:07,  7.67it/s]\u001b[A\n",
            "Iteration:   6% 1536/26921 [03:34<55:07,  7.67it/s]\u001b[A\n",
            "Iteration:  11% 3058/26921 [06:40<51:58,  7.65it/s]\u001b[A\n",
            "Iteration:  11% 3058/26921 [06:54<51:58,  7.65it/s]\u001b[A\n",
            "Iteration:  17% 4694/26921 [10:00<47:28,  7.80it/s]\u001b[A\n",
            "Iteration:  17% 4694/26921 [10:14<47:28,  7.80it/s]\u001b[A\n",
            "Iteration:  23% 6311/26921 [13:20<43:34,  7.88it/s]\u001b[A\n",
            "Iteration:  23% 6311/26921 [13:34<43:34,  7.88it/s]\u001b[A\n",
            "Iteration:  29% 7920/26921 [16:40<39:55,  7.93it/s]\u001b[A\n",
            "Iteration:  29% 7920/26921 [16:54<39:55,  7.93it/s]\u001b[A\n",
            "Iteration:  35% 9524/26921 [20:00<36:26,  7.96it/s]\u001b[A\n",
            "Iteration:  35% 9524/26921 [20:14<36:26,  7.96it/s]\u001b[A\n",
            "Iteration:  41% 11108/26921 [23:20<33:10,  7.94it/s]\u001b[A\n",
            "Iteration:  41% 11108/26921 [23:34<33:10,  7.94it/s]\u001b[A12/12/2020 05:14:24 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 05:14:27 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 05:14:27 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  47% 12653/26921 [26:41<30:12,  7.87it/s]\u001b[A\n",
            "Iteration:  47% 12653/26921 [26:54<30:12,  7.87it/s]\u001b[A\n",
            "Iteration:  53% 14197/26921 [30:01<27:05,  7.83it/s]\u001b[A\n",
            "Iteration:  53% 14197/26921 [30:14<27:05,  7.83it/s]\u001b[A\n",
            "Iteration:  58% 15747/26921 [33:21<23:52,  7.80it/s]\u001b[A\n",
            "Iteration:  58% 15747/26921 [33:34<23:52,  7.80it/s]\u001b[A\n",
            "Iteration:  64% 17301/26921 [36:41<20:34,  7.79it/s]\u001b[A\n",
            "Iteration:  64% 17301/26921 [36:54<20:34,  7.79it/s]\u001b[A\n",
            "Iteration:  70% 18946/26921 [40:01<16:47,  7.92it/s]\u001b[A\n",
            "Iteration:  70% 18946/26921 [40:14<16:47,  7.92it/s]\u001b[A\n",
            "Iteration:  76% 20536/26921 [43:21<13:25,  7.92it/s]\u001b[A\n",
            "Iteration:  76% 20536/26921 [43:34<13:25,  7.92it/s]\u001b[A\n",
            "Iteration:  82% 22095/26921 [46:41<10:12,  7.89it/s]\u001b[A\n",
            "Iteration:  82% 22095/26921 [46:54<10:12,  7.89it/s]\u001b[A\n",
            "Iteration:  88% 23680/26921 [50:01<06:50,  7.90it/s]\u001b[A\n",
            "Iteration:  88% 23680/26921 [50:14<06:50,  7.90it/s]\u001b[A12/12/2020 05:41:37 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 05:41:39 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 05:41:39 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  94% 25240/26921 [53:21<03:33,  7.87it/s]\u001b[A\n",
            "Iteration:  94% 25240/26921 [53:34<03:33,  7.87it/s]\u001b[A\n",
            "Iteration: 100% 26921/26921 [56:50<00:00,  7.89it/s]\n",
            "Epoch: 100% 2/2 [1:54:26<00:00, 3433.29s/it]\n",
            "12/12/2020 05:47:04 - INFO - transformers.configuration_utils -   loading configuration file game_bert_model_save_dir1/config.json\n",
            "12/12/2020 05:47:04 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==6\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/12/2020 05:47:04 - INFO - transformers.modeling_utils -   loading weights file game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 05:47:06 - INFO - trainer -   ***** Model Loaded *****\n",
            "12/12/2020 05:47:06 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "12/12/2020 05:47:06 - INFO - trainer -     Num examples = 8974\n",
            "12/12/2020 05:47:06 - INFO - trainer -     Batch size = 1\n",
            "Evaluating: 100% 8974/8974 [02:39<00:00, 56.26it/s]\n",
            "12/12/2020 05:49:47 - INFO - trainer -   ***** Eval results *****\n",
            "12/12/2020 05:49:47 - INFO - trainer -     intent_acc = 0.9213282817026966\n",
            "12/12/2020 05:49:47 - INFO - trainer -     loss = 0.2755181196746652\n",
            "12/12/2020 05:49:47 - INFO - trainer -     sementic_frame_acc = 0.15121462001337196\n",
            "12/12/2020 05:49:47 - INFO - trainer -     slot_f1 = 0.018973214285714288\n",
            "12/12/2020 05:49:47 - INFO - trainer -     slot_precision = 0.020161290322580645\n",
            "12/12/2020 05:49:47 - INFO - trainer -     slot_recall = 0.01791736930860034\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmyRyZ4ruWuq"
      },
      "source": [
        "# context model epoch 2 with depth = all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q959q4DjuZdk",
        "outputId": "791128b9-ba1b-403f-d790-948c42b40134"
      },
      "source": [
        "!python3 main.py --task 45k_context_depth==ALL \\\n",
        "--model_type bert \\\n",
        "--model_dir game_bert_model_save_dir1 \\\n",
        "--do_train \\\n",
        "--gradient_accumulation_steps 64 \\\n",
        "--do_eval \\\n",
        "--num_train_epochs 2 \\\n",
        "--logging_steps -1 \\\n",
        "--max_seq_len 100 \\\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-12 05:49:49.220691: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "12/12/2020 05:49:51 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "12/12/2020 05:49:52 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 05:49:52 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==ALL/train\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   guid: train-0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   guid: train-1\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   tokens: [CLS] g ##g [SEP]\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   input_ids: 101 1043 2290 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   guid: train-2\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   tokens: [CLS] g ##g [ sep ##a ] nice late game [SEP]\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   input_ids: 101 1043 2290 1031 19802 2050 1033 3835 2397 2208 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   slot_labels: 0 5 0 8 0 0 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   guid: train-3\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   tokens: [CLS] fu ##k [SEP]\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   input_ids: 101 11865 2243 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   intent_label: 2 (id = 2)\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   slot_labels: 0 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   guid: train-4\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   tokens: [CLS] ; ) [SEP]\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   input_ids: 101 1025 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:49:54 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/12/2020 05:49:59 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/12/2020 05:50:03 - INFO - data_loader -   Saving features into cached file ./data/cached_train_45k_context_depth==ALL_bert-base-uncased_100\n",
            "12/12/2020 05:50:09 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 05:50:09 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==ALL/dev\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   guid: dev-0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   tokens: [CLS] def ##f [SEP]\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   input_ids: 101 13366 2546 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   guid: dev-1\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   tokens: [CLS] su ##p [SEP]\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   input_ids: 101 10514 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   guid: dev-2\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   tokens: [CLS] like i sad [ sep ##a ] buy back to dead [SEP]\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   input_ids: 101 2066 1045 6517 1031 19802 2050 1033 4965 2067 2000 2757 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   slot_labels: 0 2 3 2 8 0 0 0 2 5 2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   guid: dev-3\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   tokens: [CLS] hi aba [SEP]\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   input_ids: 101 7632 19557 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   guid: dev-4\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   tokens: [CLS] kiss u [SEP]\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   input_ids: 101 3610 1057 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   slot_labels: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:10 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/12/2020 05:50:11 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/12/2020 05:50:12 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_45k_context_depth==ALL_bert-base-uncased_100\n",
            "12/12/2020 05:50:13 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "12/12/2020 05:50:13 - INFO - data_loader -   LOOKING AT ./data/45k_context_depth==ALL/test\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   guid: test-0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   tokens: [CLS] def ##f [SEP]\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   input_ids: 101 13366 2546 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   guid: test-1\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   tokens: [CLS] su ##p [SEP]\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   input_ids: 101 10514 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   guid: test-2\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   tokens: [CLS] like i sad [ sep ##a ] buy back to dead [SEP]\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   input_ids: 101 2066 1045 6517 1031 19802 2050 1033 4965 2067 2000 2757 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   slot_labels: 0 2 3 2 8 0 0 0 2 5 2 7 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   guid: test-3\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   tokens: [CLS] hi aba [SEP]\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   input_ids: 101 7632 19557 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   *** Example ***\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   guid: test-4\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   tokens: [CLS] kiss u [SEP]\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   input_ids: 101 3610 1057 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   slot_labels: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/12/2020 05:50:14 - INFO - data_loader -   Writing example 100 of 8974\n",
            "12/12/2020 05:50:15 - INFO - data_loader -   Writing example 5100 of 8974\n",
            "12/12/2020 05:50:16 - INFO - data_loader -   Saving features into cached file ./data/cached_test_45k_context_depth==ALL_bert-base-uncased_100\n",
            "12/12/2020 05:50:18 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "12/12/2020 05:50:18 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==ALL\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/12/2020 05:50:18 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "12/12/2020 05:50:21 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "12/12/2020 05:50:21 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "12/12/2020 05:50:27 - INFO - trainer -   ***** Running training *****\n",
            "12/12/2020 05:50:27 - INFO - trainer -     Num examples = 8974\n",
            "12/12/2020 05:50:27 - INFO - trainer -     Num Epochs = 2\n",
            "12/12/2020 05:50:27 - INFO - trainer -     Total train batch size = 1\n",
            "12/12/2020 05:50:27 - INFO - trainer -     Gradient Accumulation steps = 64\n",
            "12/12/2020 05:50:27 - INFO - trainer -     Total optimization steps = 280\n",
            "12/12/2020 05:50:27 - INFO - trainer -     Logging steps = -1\n",
            "12/12/2020 05:50:27 - INFO - trainer -     Save steps = 200\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/8974 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:  11% 946/8974 [03:20<28:17,  4.73it/s]\u001b[A\n",
            "Iteration:  11% 946/8974 [03:40<28:17,  4.73it/s]\u001b[A\n",
            "Iteration:  21% 1860/8974 [06:40<25:20,  4.68it/s]\u001b[A\n",
            "Iteration:  21% 1860/8974 [07:00<25:20,  4.68it/s]\u001b[A\n",
            "Iteration:  30% 2723/8974 [10:00<22:49,  4.56it/s]\u001b[A\n",
            "Iteration:  30% 2723/8974 [10:20<22:49,  4.56it/s]\u001b[A\n",
            "Iteration:  40% 3634/8974 [13:20<19:30,  4.56it/s]\u001b[A\n",
            "Iteration:  40% 3634/8974 [13:40<19:30,  4.56it/s]\u001b[A\n",
            "Iteration:  51% 4532/8974 [16:40<16:18,  4.54it/s]\u001b[A\n",
            "Iteration:  51% 4532/8974 [17:00<16:18,  4.54it/s]\u001b[A\n",
            "Iteration:  61% 5451/8974 [20:00<12:53,  4.55it/s]\u001b[A\n",
            "Iteration:  61% 5451/8974 [20:20<12:53,  4.55it/s]\u001b[A\n",
            "Iteration:  71% 6331/8974 [23:21<09:47,  4.50it/s]\u001b[A\n",
            "Iteration:  71% 6331/8974 [23:40<09:47,  4.50it/s]\u001b[A\n",
            "Iteration:  80% 7221/8974 [26:41<06:31,  4.48it/s]\u001b[A\n",
            "Iteration:  80% 7221/8974 [27:00<06:31,  4.48it/s]\u001b[A\n",
            "Iteration:  90% 8111/8974 [30:01<03:12,  4.47it/s]\u001b[A\n",
            "Iteration: 100% 8974/8974 [33:16<00:00,  4.49it/s]\n",
            "Epoch:  50% 1/2 [33:16<33:16, 1996.61s/it]\n",
            "Iteration:   0% 0/8974 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:  10% 907/8974 [03:20<29:39,  4.53it/s]\u001b[A\n",
            "Iteration:  10% 907/8974 [03:33<29:39,  4.53it/s]\u001b[A\n",
            "Iteration:  20% 1816/8974 [06:40<26:17,  4.54it/s]\u001b[A\n",
            "Iteration:  20% 1816/8974 [06:53<26:17,  4.54it/s]\u001b[A\n",
            "Iteration:  30% 2650/8974 [10:00<23:51,  4.42it/s]\u001b[A\n",
            "Iteration:  30% 2650/8974 [10:13<23:51,  4.42it/s]\u001b[A\n",
            "Iteration:  38% 3454/8974 [13:21<21:28,  4.28it/s]\u001b[A\n",
            "Iteration:  38% 3454/8974 [13:33<21:28,  4.28it/s]\u001b[A12/12/2020 06:38:36 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir1/config.json\n",
            "12/12/2020 06:38:38 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 06:38:38 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir1\n",
            "\n",
            "Iteration:  48% 4316/8974 [16:41<18:05,  4.29it/s]\u001b[A\n",
            "Iteration:  48% 4316/8974 [16:53<18:05,  4.29it/s]\u001b[A\n",
            "Iteration:  59% 5250/8974 [20:01<14:06,  4.40it/s]\u001b[A\n",
            "Iteration:  59% 5250/8974 [20:13<14:06,  4.40it/s]\u001b[A\n",
            "Iteration:  68% 6105/8974 [23:21<10:58,  4.36it/s]\u001b[A\n",
            "Iteration:  68% 6105/8974 [23:33<10:58,  4.36it/s]\u001b[A\n",
            "Iteration:  78% 7013/8974 [26:41<07:24,  4.41it/s]\u001b[A\n",
            "Iteration:  78% 7013/8974 [26:53<07:24,  4.41it/s]\u001b[A\n",
            "Iteration:  88% 7928/8974 [30:02<03:54,  4.46it/s]\u001b[A\n",
            "Iteration:  88% 7928/8974 [30:13<03:54,  4.46it/s]\u001b[A\n",
            "Iteration:  99% 8858/8974 [33:22<00:25,  4.51it/s]\u001b[A\n",
            "Iteration: 100% 8974/8974 [33:45<00:00,  4.43it/s]\n",
            "Epoch: 100% 2/2 [1:07:01<00:00, 2010.86s/it]\n",
            "12/12/2020 06:57:28 - INFO - transformers.configuration_utils -   loading configuration file game_bert_model_save_dir1/config.json\n",
            "12/12/2020 06:57:28 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"45k_context_depth==ALL\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/12/2020 06:57:28 - INFO - transformers.modeling_utils -   loading weights file game_bert_model_save_dir1/pytorch_model.bin\n",
            "12/12/2020 06:57:31 - INFO - trainer -   ***** Model Loaded *****\n",
            "12/12/2020 06:57:31 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "12/12/2020 06:57:31 - INFO - trainer -     Num examples = 8974\n",
            "12/12/2020 06:57:31 - INFO - trainer -     Batch size = 1\n",
            "Evaluating: 100% 8974/8974 [02:47<00:00, 53.70it/s]\n",
            "12/12/2020 07:00:19 - INFO - trainer -   ***** Eval results *****\n",
            "12/12/2020 07:00:19 - INFO - trainer -     intent_acc = 0.9102964118564743\n",
            "12/12/2020 07:00:19 - INFO - trainer -     loss = 0.32779707083045184\n",
            "12/12/2020 07:00:19 - INFO - trainer -     sementic_frame_acc = 0.06340539335859148\n",
            "12/12/2020 07:00:19 - INFO - trainer -     slot_f1 = 0.03966416750164115\n",
            "12/12/2020 07:00:19 - INFO - trainer -     slot_precision = 0.03901842158928693\n",
            "12/12/2020 07:00:19 - INFO - trainer -     slot_recall = 0.040331646992692524\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yV8KEfZOD7C"
      },
      "source": [
        "# context model do separate epoch 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oz6zEOHOGwz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28b9db2e-bf8f-4317-ee5f-65bf83419b3e"
      },
      "source": [
        "!python3 main.py --task standard_dota50k \\\n",
        "--model_type bert \\\n",
        "--model_dir game_bert_model_save_dir4 \\\n",
        "--do_separate 1 \\\n",
        "--do_train \\\n",
        "--gradient_accumulation_steps 64 \\\n",
        "--do_eval \\\n",
        "--num_train_epochs 2 \\\n",
        "--logging_steps -1 \\\n",
        "--max_seq_len 100 \\\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-15 23:33:39.136911: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/15/2020 23:33:41 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "11/15/2020 23:33:41 - INFO - data_loader -   Loading features from cached file ./data/cached_train_standard_dota50k_bert-base-uncased_100\n",
            "11/15/2020 23:33:45 - INFO - data_loader -   Loading features from cached file ./data/cached_dev_standard_dota50k_bert-base-uncased_100\n",
            "11/15/2020 23:33:46 - INFO - data_loader -   Loading features from cached file ./data/cached_test_standard_dota50k_bert-base-uncased_100\n",
            "11/15/2020 23:33:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "11/15/2020 23:33:48 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"standard_dota50k\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/15/2020 23:33:49 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "11/15/2020 23:33:52 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier_for_one_utterance.linear.weight', 'intent_classifier_for_one_utterance.linear.bias', 'intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "11/15/2020 23:33:52 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "11/15/2020 23:33:58 - INFO - trainer -   ***** Running training *****\n",
            "11/15/2020 23:33:58 - INFO - trainer -     Num examples = 29080\n",
            "11/15/2020 23:33:58 - INFO - trainer -     Num Epochs = 2\n",
            "11/15/2020 23:33:58 - INFO - trainer -     Total train batch size = 1\n",
            "11/15/2020 23:33:58 - INFO - trainer -     Gradient Accumulation steps = 64\n",
            "11/15/2020 23:33:58 - INFO - trainer -     Total optimization steps = 908\n",
            "11/15/2020 23:33:58 - INFO - trainer -     Logging steps = -1\n",
            "11/15/2020 23:33:58 - INFO - trainer -     Save steps = 200\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/29080 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   9% 2543/29080 [03:20<34:47, 12.71it/s]\u001b[A\n",
            "Iteration:   9% 2543/29080 [03:30<34:47, 12.71it/s]\u001b[A\n",
            "Iteration:  17% 5080/29080 [06:40<31:29, 12.70it/s]\u001b[A\n",
            "Iteration:  17% 5080/29080 [07:00<31:29, 12.70it/s]\u001b[A\n",
            "Iteration:  26% 7601/29080 [10:00<28:14, 12.67it/s]\u001b[A\n",
            "Iteration:  26% 7601/29080 [10:20<28:14, 12.67it/s]\u001b[A\n",
            "Iteration:  35% 10136/29080 [13:20<24:54, 12.67it/s]\u001b[A\n",
            "Iteration:  35% 10136/29080 [13:40<24:54, 12.67it/s]\u001b[A\n",
            "Iteration:  43% 12617/29080 [16:40<21:47, 12.59it/s]\u001b[A11/15/2020 23:50:52 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir4/config.json\n",
            "\n",
            "Iteration:  43% 12617/29080 [17:00<21:47, 12.59it/s]\u001b[A11/15/2020 23:51:03 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir4/pytorch_model.bin\n",
            "11/15/2020 23:51:04 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir4\n",
            "\n",
            "Iteration:  51% 14920/29080 [20:00<19:16, 12.25it/s]\u001b[A\n",
            "Iteration:  51% 14920/29080 [20:20<19:16, 12.25it/s]\u001b[A\n",
            "Iteration:  60% 17436/29080 [23:20<15:43, 12.34it/s]\u001b[A\n",
            "Iteration:  60% 17436/29080 [23:40<15:43, 12.34it/s]\u001b[A\n",
            "Iteration:  69% 19953/29080 [26:40<12:15, 12.42it/s]\u001b[A\n",
            "Iteration:  69% 19953/29080 [27:00<12:15, 12.42it/s]\u001b[A\n",
            "Iteration:  77% 22465/29080 [30:00<08:50, 12.46it/s]\u001b[A\n",
            "Iteration:  77% 22465/29080 [30:20<08:50, 12.46it/s]\u001b[A\n",
            "Iteration:  86% 24998/29080 [33:20<05:26, 12.52it/s]\u001b[A\n",
            "Iteration:  86% 24998/29080 [33:40<05:26, 12.52it/s]\u001b[A11/16/2020 00:08:07 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir4/config.json\n",
            "11/16/2020 00:08:09 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir4/pytorch_model.bin\n",
            "11/16/2020 00:08:09 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir4\n",
            "\n",
            "Iteration:  95% 27500/29080 [36:40<02:06, 12.51it/s]\u001b[A\n",
            "Iteration: 100% 29080/29080 [38:38<00:00, 12.54it/s]\n",
            "Epoch:  50% 1/2 [38:38<38:38, 2318.71s/it]\n",
            "Iteration:   0% 0/29080 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   9% 2676/29080 [03:20<32:53, 13.38it/s]\u001b[A\n",
            "Iteration:   9% 2676/29080 [03:31<32:53, 13.38it/s]\u001b[A\n",
            "Iteration:  18% 5350/29080 [06:40<29:34, 13.37it/s]\u001b[A\n",
            "Iteration:  18% 5350/29080 [06:51<29:34, 13.37it/s]\u001b[A\n",
            "Iteration:  27% 7973/29080 [10:00<26:27, 13.29it/s]\u001b[A\n",
            "Iteration:  27% 7973/29080 [10:11<26:27, 13.29it/s]\u001b[A11/16/2020 00:24:21 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir4/config.json\n",
            "11/16/2020 00:24:23 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir4/pytorch_model.bin\n",
            "11/16/2020 00:24:23 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir4\n",
            "\n",
            "Iteration:  36% 10547/29080 [13:20<23:27, 13.16it/s]\u001b[A\n",
            "Iteration:  36% 10547/29080 [13:31<23:27, 13.16it/s]\u001b[A\n",
            "Iteration:  45% 13212/29080 [16:40<20:01, 13.21it/s]\u001b[A\n",
            "Iteration:  45% 13212/29080 [16:51<20:01, 13.21it/s]\u001b[A\n",
            "Iteration:  54% 15841/29080 [20:00<16:43, 13.19it/s]\u001b[A\n",
            "Iteration:  54% 15841/29080 [20:11<16:43, 13.19it/s]\u001b[A\n",
            "Iteration:  64% 18506/29080 [23:20<13:19, 13.23it/s]\u001b[A\n",
            "Iteration:  64% 18506/29080 [23:31<13:19, 13.23it/s]\u001b[A\n",
            "Iteration:  73% 21203/29080 [26:40<09:52, 13.30it/s]\u001b[A\n",
            "Iteration:  73% 21203/29080 [26:51<09:52, 13.30it/s]\u001b[A11/16/2020 00:40:28 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir4/config.json\n",
            "11/16/2020 00:40:31 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir4/pytorch_model.bin\n",
            "11/16/2020 00:40:31 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir4\n",
            "\n",
            "Iteration:  82% 23756/29080 [30:00<06:45, 13.14it/s]\u001b[A\n",
            "Iteration:  82% 23756/29080 [30:11<06:45, 13.14it/s]\u001b[A\n",
            "Iteration:  90% 26310/29080 [33:20<03:32, 13.02it/s]\u001b[A\n",
            "Iteration:  90% 26310/29080 [33:31<03:32, 13.02it/s]\u001b[A\n",
            "Iteration:  99% 28797/29080 [36:40<00:22, 12.84it/s]\u001b[A\n",
            "Iteration: 100% 29080/29080 [37:03<00:00, 13.08it/s]\n",
            "Epoch: 100% 2/2 [1:15:41<00:00, 2270.88s/it]\n",
            "11/16/2020 00:49:39 - INFO - transformers.configuration_utils -   loading configuration file game_bert_model_save_dir4/config.json\n",
            "11/16/2020 00:49:39 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"standard_dota50k\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/16/2020 00:49:39 - INFO - transformers.modeling_utils -   loading weights file game_bert_model_save_dir4/pytorch_model.bin\n",
            "11/16/2020 00:49:42 - INFO - trainer -   ***** Model Loaded *****\n",
            "11/16/2020 00:49:42 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "11/16/2020 00:49:42 - INFO - trainer -     Num examples = 9687\n",
            "11/16/2020 00:49:42 - INFO - trainer -     Batch size = 1\n",
            "Evaluating: 100% 9687/9687 [05:49<00:00, 27.71it/s]\n",
            "11/16/2020 00:55:33 - INFO - trainer -   ***** Eval results *****\n",
            "11/16/2020 00:55:33 - INFO - trainer -     intent_acc = 0.8985237947765046\n",
            "11/16/2020 00:55:33 - INFO - trainer -     loss = 0.3343163597054954\n",
            "11/16/2020 00:55:33 - INFO - trainer -     sementic_frame_acc = 0.0257045524930319\n",
            "11/16/2020 00:55:33 - INFO - trainer -     slot_f1 = 0.011188909609091868\n",
            "11/16/2020 00:55:33 - INFO - trainer -     slot_precision = 0.011400301140030114\n",
            "11/16/2020 00:55:33 - INFO - trainer -     slot_recall = 0.010985214868039243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a7ngNtrUdZD"
      },
      "source": [
        "# context model with depth 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQA8-QHKUgEC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f006104-10bb-4486-f8b9-9429df0e7dd4"
      },
      "source": [
        "!python3 main.py --task standard_dota50k_context_depth=3 \\\n",
        "--model_type bert \\\n",
        "--model_dir game_bert_model_save_dir3 \\\n",
        "--do_train \\\n",
        "--gradient_accumulation_steps 64 \\\n",
        "--do_eval \\\n",
        "--num_train_epochs 2 \\\n",
        "--logging_steps -1 \\\n",
        "--max_seq_len 100 \\\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-16 00:55:40.360579: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/16/2020 00:55:43 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "11/16/2020 00:55:44 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/16/2020 00:55:44 - INFO - data_loader -   LOOKING AT ./data/standard_dota50k_context_depth=3/train\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   guid: train-0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   tokens: [CLS] 0 [SEP]\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   intent_label: 0 (id = 0)\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   slot_labels: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   guid: train-1\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   tokens: [CLS] < 3 [ sep ##a ] : ) [SEP]\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   input_ids: 101 1026 1017 1031 19802 2050 1033 1024 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   slot_labels: 0 2 0 8 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   guid: train-2\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   tokens: [CLS] report puck pl ##s [SEP]\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   input_ids: 101 3189 22900 20228 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   intent_label: 2 (id = 2)\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   slot_labels: 0 5 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   guid: train-3\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   tokens: [CLS] e ##z [SEP]\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   input_ids: 101 1041 2480 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   guid: train-4\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   tokens: [CLS] no ##ob 1 8 k mm ##r [ sep ##a ] i am 4 mm ##r [ sep ##a ] 4 k [SEP]\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   input_ids: 101 2053 16429 1015 1022 1047 3461 2099 1031 19802 2050 1033 1045 2572 1018 3461 2099 1031 19802 2050 1033 1018 1047 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   intent_label: 2 (id = 2)\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   slot_labels: 0 7 0 2 2 2 2 0 8 0 0 0 3 4 2 2 0 8 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:55:46 - INFO - data_loader -   Writing example 100 of 29080\n",
            "11/16/2020 00:55:49 - INFO - data_loader -   Writing example 5100 of 29080\n",
            "11/16/2020 00:55:51 - INFO - data_loader -   Writing example 10100 of 29080\n",
            "11/16/2020 00:55:54 - INFO - data_loader -   Writing example 15100 of 29080\n",
            "11/16/2020 00:55:56 - INFO - data_loader -   Writing example 20100 of 29080\n",
            "11/16/2020 00:55:59 - INFO - data_loader -   Writing example 25100 of 29080\n",
            "11/16/2020 00:56:01 - INFO - data_loader -   Saving features into cached file ./data/cached_train_standard_dota50k_context_depth=3_bert-base-uncased_100\n",
            "11/16/2020 00:56:10 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/16/2020 00:56:10 - INFO - data_loader -   LOOKING AT ./data/standard_dota50k_context_depth=3/dev\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   guid: dev-0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   tokens: [CLS] 0 [SEP]\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   intent_label: 0 (id = 0)\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   slot_labels: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   guid: dev-1\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   tokens: [CLS] 60 [SEP]\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   input_ids: 101 3438 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   guid: dev-2\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   tokens: [CLS] : d [SEP]\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   input_ids: 101 1024 1040 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   guid: dev-3\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   tokens: [CLS] don ##t be mad ns [SEP]\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   input_ids: 101 2123 2102 2022 5506 24978 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   slot_labels: 0 2 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   guid: dev-4\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   tokens: [CLS] sector clear [SEP]\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   input_ids: 101 4753 3154 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:12 - INFO - data_loader -   Writing example 100 of 9668\n",
            "11/16/2020 00:56:15 - INFO - data_loader -   Writing example 5100 of 9668\n",
            "11/16/2020 00:56:17 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_standard_dota50k_context_depth=3_bert-base-uncased_100\n",
            "11/16/2020 00:56:20 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/16/2020 00:56:20 - INFO - data_loader -   LOOKING AT ./data/standard_dota50k_context_depth=3/test\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   guid: test-0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   tokens: [CLS] 0 [SEP]\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   intent_label: 0 (id = 0)\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   slot_labels: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   guid: test-1\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   tokens: [CLS] ok so g ##l catch him next game [SEP]\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   input_ids: 101 7929 2061 1043 2140 4608 2032 2279 2208 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   slot_labels: 0 2 2 2 0 2 3 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   guid: test-2\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   tokens: [CLS] l ##ma ##o [SEP]\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   input_ids: 101 1048 2863 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   attention_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   guid: test-3\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   tokens: [CLS] sec [ sep ##a ] ye ##a [SEP]\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   input_ids: 101 10819 1031 19802 2050 1033 6300 2050 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   slot_labels: 0 2 8 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   guid: test-4\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   tokens: [CLS] g ##g w ##p [SEP]\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   input_ids: 101 1043 2290 1059 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   slot_labels: 0 5 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 00:56:24 - INFO - data_loader -   Writing example 100 of 9687\n",
            "11/16/2020 00:56:26 - INFO - data_loader -   Writing example 5100 of 9687\n",
            "11/16/2020 00:56:28 - INFO - data_loader -   Saving features into cached file ./data/cached_test_standard_dota50k_context_depth=3_bert-base-uncased_100\n",
            "11/16/2020 00:56:32 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "11/16/2020 00:56:32 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"standard_dota50k_context_depth=3\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/16/2020 00:56:33 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "11/16/2020 00:56:36 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "11/16/2020 00:56:36 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "11/16/2020 00:56:42 - INFO - trainer -   ***** Running training *****\n",
            "11/16/2020 00:56:42 - INFO - trainer -     Num examples = 29080\n",
            "11/16/2020 00:56:42 - INFO - trainer -     Num Epochs = 2\n",
            "11/16/2020 00:56:42 - INFO - trainer -     Total train batch size = 1\n",
            "11/16/2020 00:56:42 - INFO - trainer -     Gradient Accumulation steps = 64\n",
            "11/16/2020 00:56:42 - INFO - trainer -     Total optimization steps = 908\n",
            "11/16/2020 00:56:42 - INFO - trainer -     Logging steps = -1\n",
            "11/16/2020 00:56:42 - INFO - trainer -     Save steps = 200\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/29080 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   7% 2034/29080 [03:20<44:19, 10.17it/s]\u001b[A\n",
            "Iteration:   7% 2034/29080 [03:30<44:19, 10.17it/s]\u001b[A\n",
            "Iteration:  14% 4097/29080 [06:40<40:46, 10.21it/s]\u001b[A\n",
            "Iteration:  14% 4097/29080 [07:00<40:46, 10.21it/s]\u001b[A\n",
            "Iteration:  21% 6123/29080 [10:00<37:33, 10.19it/s]\u001b[A\n",
            "Iteration:  21% 6123/29080 [10:20<37:33, 10.19it/s]\u001b[A\n",
            "Iteration:  28% 8144/29080 [13:20<34:20, 10.16it/s]\u001b[A\n",
            "Iteration:  28% 8144/29080 [13:40<34:20, 10.16it/s]\u001b[A\n",
            "Iteration:  35% 10152/29080 [16:40<31:09, 10.12it/s]\u001b[A\n",
            "Iteration:  35% 10152/29080 [17:00<31:09, 10.12it/s]\u001b[A\n",
            "Iteration:  42% 12174/29080 [20:00<27:50, 10.12it/s]\u001b[A\n",
            "Iteration:  42% 12174/29080 [20:20<27:50, 10.12it/s]\u001b[A11/16/2020 01:17:44 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 01:17:55 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 01:17:56 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  48% 14060/29080 [23:20<25:17,  9.90it/s]\u001b[A\n",
            "Iteration:  48% 14060/29080 [23:40<25:17,  9.90it/s]\u001b[A\n",
            "Iteration:  55% 16070/29080 [26:40<21:48,  9.94it/s]\u001b[A\n",
            "Iteration:  55% 16070/29080 [27:00<21:48,  9.94it/s]\u001b[A\n",
            "Iteration:  62% 18061/29080 [30:00<18:27,  9.95it/s]\u001b[A\n",
            "Iteration:  62% 18061/29080 [30:20<18:27,  9.95it/s]\u001b[A\n",
            "Iteration:  69% 20075/29080 [33:20<15:02,  9.98it/s]\u001b[A\n",
            "Iteration:  69% 20075/29080 [33:40<15:02,  9.98it/s]\u001b[A\n",
            "Iteration:  76% 22096/29080 [36:40<11:37, 10.02it/s]\u001b[A\n",
            "Iteration:  76% 22096/29080 [37:00<11:37, 10.02it/s]\u001b[A\n",
            "Iteration:  83% 24168/29080 [40:00<08:05, 10.12it/s]\u001b[A\n",
            "Iteration:  83% 24168/29080 [40:20<08:05, 10.12it/s]\u001b[A11/16/2020 01:39:02 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 01:39:04 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 01:39:04 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  90% 26186/29080 [43:20<04:46, 10.11it/s]\u001b[A\n",
            "Iteration:  90% 26186/29080 [43:40<04:46, 10.11it/s]\u001b[A\n",
            "Iteration:  97% 28214/29080 [46:40<01:25, 10.12it/s]\u001b[A\n",
            "Iteration: 100% 29080/29080 [48:05<00:00, 10.08it/s]\n",
            "Epoch:  50% 1/2 [48:05<48:05, 2885.43s/it]\n",
            "Iteration:   0% 0/29080 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   7% 2005/29080 [03:20<45:00, 10.02it/s]\u001b[A\n",
            "Iteration:   7% 2005/29080 [03:34<45:00, 10.02it/s]\u001b[A\n",
            "Iteration:  14% 4048/29080 [06:40<41:23, 10.08it/s]\u001b[A\n",
            "Iteration:  14% 4048/29080 [06:54<41:23, 10.08it/s]\u001b[A\n",
            "Iteration:  21% 6081/29080 [10:00<37:56, 10.10it/s]\u001b[A\n",
            "Iteration:  21% 6081/29080 [10:14<37:56, 10.10it/s]\u001b[A\n",
            "Iteration:  28% 8153/29080 [13:20<34:15, 10.18it/s]\u001b[A\n",
            "Iteration:  28% 8153/29080 [13:34<34:15, 10.18it/s]\u001b[A11/16/2020 02:00:02 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 02:00:04 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 02:00:04 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  35% 10196/29080 [16:40<30:53, 10.19it/s]\u001b[A\n",
            "Iteration:  35% 10196/29080 [16:54<30:53, 10.19it/s]\u001b[A\n",
            "Iteration:  42% 12209/29080 [20:00<27:41, 10.15it/s]\u001b[A\n",
            "Iteration:  42% 12209/29080 [20:14<27:41, 10.15it/s]\u001b[A\n",
            "Iteration:  49% 14250/29080 [23:20<24:18, 10.17it/s]\u001b[A\n",
            "Iteration:  49% 14250/29080 [23:34<24:18, 10.17it/s]\u001b[A\n",
            "Iteration:  56% 16325/29080 [26:40<20:47, 10.23it/s]\u001b[A\n",
            "Iteration:  56% 16325/29080 [26:54<20:47, 10.23it/s]\u001b[A\n",
            "Iteration:  63% 18374/29080 [30:00<17:26, 10.23it/s]\u001b[A\n",
            "Iteration:  63% 18374/29080 [30:14<17:26, 10.23it/s]\u001b[A\n",
            "Iteration:  70% 20411/29080 [33:20<14:08, 10.22it/s]\u001b[A\n",
            "Iteration:  70% 20411/29080 [33:34<14:08, 10.22it/s]\u001b[A11/16/2020 02:21:01 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 02:21:03 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 02:21:03 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  77% 22371/29080 [36:40<11:05, 10.09it/s]\u001b[A\n",
            "Iteration:  77% 22371/29080 [36:54<11:05, 10.09it/s]\u001b[A\n",
            "Iteration:  84% 24372/29080 [40:00<07:47, 10.06it/s]\u001b[A\n",
            "Iteration:  84% 24372/29080 [40:14<07:47, 10.06it/s]\u001b[A\n",
            "Iteration:  91% 26376/29080 [43:20<04:29, 10.05it/s]\u001b[A\n",
            "Iteration:  91% 26376/29080 [43:34<04:29, 10.05it/s]\u001b[A\n",
            "Iteration:  98% 28420/29080 [46:40<01:05, 10.10it/s]\u001b[A\n",
            "Iteration: 100% 29080/29080 [47:48<00:00, 10.14it/s]\n",
            "Epoch: 100% 2/2 [1:35:53<00:00, 2876.72s/it]\n",
            "11/16/2020 02:32:35 - INFO - transformers.configuration_utils -   loading configuration file game_bert_model_save_dir3/config.json\n",
            "11/16/2020 02:32:35 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"standard_dota50k_context_depth=3\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/16/2020 02:32:35 - INFO - transformers.modeling_utils -   loading weights file game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 02:32:38 - INFO - trainer -   ***** Model Loaded *****\n",
            "11/16/2020 02:32:38 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "11/16/2020 02:32:38 - INFO - trainer -     Num examples = 9687\n",
            "11/16/2020 02:32:38 - INFO - trainer -     Batch size = 1\n",
            "Evaluating: 100% 9687/9687 [06:53<00:00, 23.42it/s]\n",
            "11/16/2020 02:39:33 - INFO - trainer -   ***** Eval results *****\n",
            "11/16/2020 02:39:33 - INFO - trainer -     intent_acc = 0.8992464127180758\n",
            "11/16/2020 02:39:33 - INFO - trainer -     loss = 0.3297219475113977\n",
            "11/16/2020 02:39:33 - INFO - trainer -     sementic_frame_acc = 0.2091462785176009\n",
            "11/16/2020 02:39:33 - INFO - trainer -     slot_f1 = 0.021983183803842357\n",
            "11/16/2020 02:39:33 - INFO - trainer -     slot_precision = 0.03433602347762289\n",
            "11/16/2020 02:39:33 - INFO - trainer -     slot_recall = 0.016166919994472846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-FW0PWmUjil"
      },
      "source": [
        "# context model with depth all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83_Cyob-UlVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8be9ac5-6b68-45d7-b0d2-9c31c7b65907"
      },
      "source": [
        "!python3 main.py --task standard_dota50k_context_depth=all \\\n",
        "--model_type bert \\\n",
        "--model_dir game_bert_model_save_dir3 \\\n",
        "--do_train \\\n",
        "--gradient_accumulation_steps 64 \\\n",
        "--do_eval \\\n",
        "--num_train_epochs 2 \\\n",
        "--logging_steps -1 \\\n",
        "--max_seq_len 100 \\\n",
        "--save_steps 200"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-16 02:39:37.282848: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "11/16/2020 02:39:40 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "11/16/2020 02:39:41 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/16/2020 02:39:41 - INFO - data_loader -   LOOKING AT ./data/standard_dota50k_context_depth=all/train\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   guid: train-0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   tokens: [CLS] 0 [SEP]\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   intent_label: 0 (id = 0)\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   slot_labels: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   guid: train-1\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   tokens: [CLS] < 3 [ sep ##a ] : ) [SEP]\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   input_ids: 101 1026 1017 1031 19802 2050 1033 1024 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   slot_labels: 0 2 0 8 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   guid: train-2\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   tokens: [CLS] report puck pl ##s [SEP]\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   input_ids: 101 3189 22900 20228 2015 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   intent_label: 2 (id = 2)\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   slot_labels: 0 5 4 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   guid: train-3\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   tokens: [CLS] e ##z [SEP]\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   input_ids: 101 1041 2480 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   slot_labels: 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   guid: train-4\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   tokens: [CLS] no ##ob 1 8 k mm ##r [ sep ##a ] i am 4 mm ##r [ sep ##a ] 4 k [SEP]\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   input_ids: 101 2053 16429 1015 1022 1047 3461 2099 1031 19802 2050 1033 1045 2572 1018 3461 2099 1031 19802 2050 1033 1018 1047 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   intent_label: 2 (id = 2)\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   slot_labels: 0 7 0 2 2 2 2 0 8 0 0 0 3 4 2 2 0 8 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:39:44 - INFO - data_loader -   Writing example 100 of 29080\n",
            "11/16/2020 02:39:50 - INFO - data_loader -   Writing example 5100 of 29080\n",
            "11/16/2020 02:39:56 - INFO - data_loader -   Writing example 10100 of 29080\n",
            "11/16/2020 02:40:01 - INFO - data_loader -   Writing example 15100 of 29080\n",
            "11/16/2020 02:40:07 - INFO - data_loader -   Writing example 20100 of 29080\n",
            "11/16/2020 02:40:13 - INFO - data_loader -   Writing example 25100 of 29080\n",
            "11/16/2020 02:40:18 - INFO - data_loader -   Saving features into cached file ./data/cached_train_standard_dota50k_context_depth=all_bert-base-uncased_100\n",
            "11/16/2020 02:40:40 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/16/2020 02:40:40 - INFO - data_loader -   LOOKING AT ./data/standard_dota50k_context_depth=all/dev\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   guid: dev-0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   tokens: [CLS] 0 [SEP]\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   intent_label: 0 (id = 0)\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   slot_labels: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   guid: dev-1\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   tokens: [CLS] 60 [SEP]\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   input_ids: 101 3438 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   guid: dev-2\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   tokens: [CLS] : d [SEP]\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   input_ids: 101 1024 1040 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   guid: dev-3\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   tokens: [CLS] don ##t be mad ns [SEP]\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   input_ids: 101 2123 2102 2022 5506 24978 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   slot_labels: 0 2 0 2 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   guid: dev-4\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   tokens: [CLS] sector clear [SEP]\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   input_ids: 101 4753 3154 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   attention_mask: 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   slot_labels: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:40:42 - INFO - data_loader -   Writing example 100 of 9668\n",
            "11/16/2020 02:40:48 - INFO - data_loader -   Writing example 5100 of 9668\n",
            "11/16/2020 02:40:53 - INFO - data_loader -   Saving features into cached file ./data/cached_dev_standard_dota50k_context_depth=all_bert-base-uncased_100\n",
            "11/16/2020 02:41:01 - INFO - data_loader -   Creating features from dataset file at ./data\n",
            "11/16/2020 02:41:01 - INFO - data_loader -   LOOKING AT ./data/standard_dota50k_context_depth=all/test\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   guid: test-0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   tokens: [CLS] 0 [SEP]\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   input_ids: 101 1014 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   attention_mask: 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   intent_label: 0 (id = 0)\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   slot_labels: 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   guid: test-1\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   tokens: [CLS] ok so g ##l catch him next game [SEP]\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   input_ids: 101 7929 2061 1043 2140 4608 2032 2279 2208 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   slot_labels: 0 2 2 2 0 2 3 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   guid: test-2\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   tokens: [CLS] l ##ma ##o [SEP]\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   input_ids: 101 1048 2863 2080 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   attention_mask: 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   slot_labels: 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   guid: test-3\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   tokens: [CLS] sec [ sep ##a ] ye ##a [SEP]\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   input_ids: 101 10819 1031 19802 2050 1033 6300 2050 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   slot_labels: 0 2 8 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   *** Example ***\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   guid: test-4\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   tokens: [CLS] g ##g w ##p [SEP]\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   input_ids: 101 1043 2290 1059 2361 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   attention_mask: 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   token_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   intent_label: 4 (id = 4)\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   slot_labels: 0 5 0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "11/16/2020 02:41:03 - INFO - data_loader -   Writing example 100 of 9687\n",
            "11/16/2020 02:41:09 - INFO - data_loader -   Writing example 5100 of 9687\n",
            "11/16/2020 02:41:14 - INFO - data_loader -   Saving features into cached file ./data/cached_test_standard_dota50k_context_depth=all_bert-base-uncased_100\n",
            "11/16/2020 02:41:22 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "11/16/2020 02:41:22 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"standard_dota50k_context_depth=all\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/16/2020 02:41:23 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "11/16/2020 02:41:26 - INFO - transformers.modeling_utils -   Weights of JointBERT not initialized from pretrained model: ['intent_classifier.linear.weight', 'intent_classifier.linear.bias', 'slot_classifier.linear.weight', 'slot_classifier.linear.bias', 'context_lstm.weight_ih_l0', 'context_lstm.weight_hh_l0', 'context_lstm.bias_ih_l0', 'context_lstm.bias_hh_l0']\n",
            "11/16/2020 02:41:26 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in JointBERT: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "11/16/2020 02:41:32 - INFO - trainer -   ***** Running training *****\n",
            "11/16/2020 02:41:32 - INFO - trainer -     Num examples = 29080\n",
            "11/16/2020 02:41:32 - INFO - trainer -     Num Epochs = 2\n",
            "11/16/2020 02:41:32 - INFO - trainer -     Total train batch size = 1\n",
            "11/16/2020 02:41:32 - INFO - trainer -     Gradient Accumulation steps = 64\n",
            "11/16/2020 02:41:32 - INFO - trainer -     Total optimization steps = 908\n",
            "11/16/2020 02:41:32 - INFO - trainer -     Logging steps = -1\n",
            "11/16/2020 02:41:32 - INFO - trainer -     Save steps = 200\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/29080 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.6/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   3% 753/29080 [03:20<2:05:34,  3.76it/s]\u001b[A\n",
            "Iteration:   3% 753/29080 [03:40<2:05:34,  3.76it/s]\u001b[A\n",
            "Iteration:   5% 1570/29080 [06:40<1:59:03,  3.85it/s]\u001b[A\n",
            "Iteration:   5% 1570/29080 [07:00<1:59:03,  3.85it/s]\u001b[A\n",
            "Iteration:   8% 2391/29080 [10:01<1:53:28,  3.92it/s]\u001b[A\n",
            "Iteration:   8% 2391/29080 [10:20<1:53:28,  3.92it/s]\u001b[A\n",
            "Iteration:  11% 3246/29080 [13:21<1:47:12,  4.02it/s]\u001b[A\n",
            "Iteration:  11% 3246/29080 [13:40<1:47:12,  4.02it/s]\u001b[A\n",
            "Iteration:  14% 4031/29080 [16:41<1:44:41,  3.99it/s]\u001b[A\n",
            "Iteration:  14% 4031/29080 [17:00<1:44:41,  3.99it/s]\u001b[A\n",
            "Iteration:  17% 4849/29080 [20:02<1:40:34,  4.02it/s]\u001b[A\n",
            "Iteration:  17% 4849/29080 [20:20<1:40:34,  4.02it/s]\u001b[A\n",
            "Iteration:  19% 5615/29080 [23:22<1:38:51,  3.96it/s]\u001b[A\n",
            "Iteration:  19% 5615/29080 [23:40<1:38:51,  3.96it/s]\u001b[A\n",
            "Iteration:  22% 6366/29080 [26:42<1:37:14,  3.89it/s]\u001b[A\n",
            "Iteration:  22% 6366/29080 [27:00<1:37:14,  3.89it/s]\u001b[A\n",
            "Iteration:  25% 7171/29080 [30:02<1:32:53,  3.93it/s]\u001b[A\n",
            "Iteration:  25% 7171/29080 [30:20<1:32:53,  3.93it/s]\u001b[A\n",
            "Iteration:  27% 7978/29080 [33:22<1:28:47,  3.96it/s]\u001b[A\n",
            "Iteration:  27% 7978/29080 [33:40<1:28:47,  3.96it/s]\u001b[A\n",
            "Iteration:  30% 8722/29080 [36:43<1:27:20,  3.89it/s]\u001b[A\n",
            "Iteration:  30% 8722/29080 [37:00<1:27:20,  3.89it/s]\u001b[A\n",
            "Iteration:  33% 9481/29080 [40:03<1:24:41,  3.86it/s]\u001b[A\n",
            "Iteration:  33% 9481/29080 [40:20<1:24:41,  3.86it/s]\u001b[A\n",
            "Iteration:  35% 10213/29080 [43:23<1:22:53,  3.79it/s]\u001b[A\n",
            "Iteration:  35% 10213/29080 [43:40<1:22:53,  3.79it/s]\u001b[A\n",
            "Iteration:  38% 10968/29080 [46:43<1:19:42,  3.79it/s]\u001b[A\n",
            "Iteration:  38% 10968/29080 [47:00<1:19:42,  3.79it/s]\u001b[A\n",
            "Iteration:  40% 11695/29080 [50:03<1:17:28,  3.74it/s]\u001b[A\n",
            "Iteration:  40% 11695/29080 [50:20<1:17:28,  3.74it/s]\u001b[A\n",
            "Iteration:  43% 12486/29080 [53:23<1:12:45,  3.80it/s]\u001b[A\n",
            "Iteration:  43% 12486/29080 [53:40<1:12:45,  3.80it/s]\u001b[A11/16/2020 03:36:19 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 03:36:21 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 03:36:21 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  46% 13249/29080 [56:45<1:09:30,  3.80it/s]\u001b[A\n",
            "Iteration:  46% 13249/29080 [57:00<1:09:30,  3.80it/s]\u001b[A\n",
            "Iteration:  48% 14014/29080 [1:00:05<1:06:02,  3.80it/s]\u001b[A\n",
            "Iteration:  48% 14014/29080 [1:00:20<1:06:02,  3.80it/s]\u001b[A\n",
            "Iteration:  51% 14781/29080 [1:03:26<1:02:36,  3.81it/s]\u001b[A\n",
            "Iteration:  51% 14781/29080 [1:03:40<1:02:36,  3.81it/s]\u001b[A\n",
            "Iteration:  54% 15609/29080 [1:06:47<57:34,  3.90it/s]  \u001b[A\n",
            "Iteration:  54% 15609/29080 [1:07:00<57:34,  3.90it/s]\u001b[A\n",
            "Iteration:  56% 16388/29080 [1:10:07<54:15,  3.90it/s]\u001b[A\n",
            "Iteration:  56% 16388/29080 [1:10:20<54:15,  3.90it/s]\u001b[A\n",
            "Iteration:  59% 17155/29080 [1:13:27<51:14,  3.88it/s]\u001b[A\n",
            "Iteration:  59% 17155/29080 [1:13:40<51:14,  3.88it/s]\u001b[A\n",
            "Iteration:  62% 17926/29080 [1:16:47<48:01,  3.87it/s]\u001b[A\n",
            "Iteration:  62% 17926/29080 [1:17:00<48:01,  3.87it/s]\u001b[A\n",
            "Iteration:  64% 18687/29080 [1:20:08<45:02,  3.85it/s]\u001b[A\n",
            "Iteration:  64% 18687/29080 [1:20:20<45:02,  3.85it/s]\u001b[A\n",
            "Iteration:  67% 19424/29080 [1:23:31<42:37,  3.78it/s]\u001b[A\n",
            "Iteration:  67% 19424/29080 [1:23:50<42:37,  3.78it/s]\u001b[A\n",
            "Iteration:  69% 20206/29080 [1:26:51<38:47,  3.81it/s]\u001b[A\n",
            "Iteration:  69% 20206/29080 [1:27:10<38:47,  3.81it/s]\u001b[A\n",
            "Iteration:  72% 20966/29080 [1:30:12<35:30,  3.81it/s]\u001b[A\n",
            "Iteration:  72% 20966/29080 [1:30:30<35:30,  3.81it/s]\u001b[A\n",
            "Iteration:  75% 21774/29080 [1:33:32<31:27,  3.87it/s]\u001b[A\n",
            "Iteration:  75% 21774/29080 [1:33:50<31:27,  3.87it/s]\u001b[A\n",
            "Iteration:  78% 22591/29080 [1:36:54<27:34,  3.92it/s]\u001b[A\n",
            "Iteration:  78% 22591/29080 [1:37:10<27:34,  3.92it/s]\u001b[A\n",
            "Iteration:  80% 23388/29080 [1:40:15<24:05,  3.94it/s]\u001b[A\n",
            "Iteration:  80% 23388/29080 [1:40:30<24:05,  3.94it/s]\u001b[A\n",
            "Iteration:  83% 24151/29080 [1:43:35<21:04,  3.90it/s]\u001b[A\n",
            "Iteration:  83% 24151/29080 [1:43:50<21:04,  3.90it/s]\u001b[A\n",
            "Iteration:  86% 24938/29080 [1:46:55<17:39,  3.91it/s]\u001b[A\n",
            "Iteration:  86% 24938/29080 [1:47:10<17:39,  3.91it/s]\u001b[A11/16/2020 04:31:13 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 04:31:16 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 04:31:16 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  89% 25743/29080 [1:50:16<14:06,  3.94it/s]\u001b[A\n",
            "Iteration:  89% 25743/29080 [1:50:30<14:06,  3.94it/s]\u001b[A\n",
            "Iteration:  91% 26475/29080 [1:53:36<11:16,  3.85it/s]\u001b[A\n",
            "Iteration:  91% 26475/29080 [1:53:50<11:16,  3.85it/s]\u001b[A\n",
            "Iteration:  94% 27276/29080 [1:56:56<07:43,  3.89it/s]\u001b[A\n",
            "Iteration:  94% 27276/29080 [1:57:10<07:43,  3.89it/s]\u001b[A\n",
            "Iteration:  96% 28022/29080 [2:00:17<04:35,  3.84it/s]\u001b[A\n",
            "Iteration:  96% 28022/29080 [2:00:30<04:35,  3.84it/s]\u001b[A\n",
            "Iteration:  99% 28803/29080 [2:03:38<01:11,  3.85it/s]\u001b[A\n",
            "Iteration: 100% 29080/29080 [2:04:46<00:00,  3.88it/s]\n",
            "Epoch:  50% 1/2 [2:04:46<2:04:46, 7486.89s/it]\n",
            "Iteration:   0% 0/29080 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   3% 812/29080 [03:20<1:56:03,  4.06it/s]\u001b[A\n",
            "Iteration:   3% 812/29080 [03:33<1:56:03,  4.06it/s]\u001b[A\n",
            "Iteration:   5% 1560/29080 [06:40<1:55:53,  3.96it/s]\u001b[A\n",
            "Iteration:   5% 1560/29080 [06:53<1:55:53,  3.96it/s]\u001b[A\n",
            "Iteration:   8% 2364/29080 [10:00<1:52:01,  3.97it/s]\u001b[A\n",
            "Iteration:   8% 2364/29080 [10:13<1:52:01,  3.97it/s]\u001b[A\n",
            "Iteration:  11% 3161/29080 [13:20<1:48:37,  3.98it/s]\u001b[A\n",
            "Iteration:  11% 3161/29080 [13:33<1:48:37,  3.98it/s]\u001b[A\n",
            "Iteration:  13% 3903/29080 [16:40<1:47:49,  3.89it/s]\u001b[A\n",
            "Iteration:  13% 3903/29080 [16:53<1:47:49,  3.89it/s]\u001b[A\n",
            "Iteration:  16% 4630/29080 [20:00<1:46:56,  3.81it/s]\u001b[A\n",
            "Iteration:  16% 4630/29080 [20:13<1:46:56,  3.81it/s]\u001b[A\n",
            "Iteration:  19% 5436/29080 [23:22<1:41:57,  3.87it/s]\u001b[A\n",
            "Iteration:  19% 5436/29080 [23:33<1:41:57,  3.87it/s]\u001b[A\n",
            "Iteration:  21% 6164/29080 [26:42<1:40:43,  3.79it/s]\u001b[A\n",
            "Iteration:  21% 6164/29080 [26:53<1:40:43,  3.79it/s]\u001b[A\n",
            "Iteration:  24% 6912/29080 [30:03<1:37:52,  3.78it/s]\u001b[A\n",
            "Iteration:  24% 6912/29080 [30:13<1:37:52,  3.78it/s]\u001b[A\n",
            "Iteration:  27% 7739/29080 [33:23<1:31:47,  3.88it/s]\u001b[A\n",
            "Iteration:  27% 7739/29080 [33:33<1:31:47,  3.88it/s]\u001b[A\n",
            "Iteration:  30% 8594/29080 [36:43<1:25:38,  3.99it/s]\u001b[A\n",
            "Iteration:  30% 8594/29080 [36:53<1:25:38,  3.99it/s]\u001b[A\n",
            "Iteration:  32% 9323/29080 [40:03<1:24:55,  3.88it/s]\u001b[A11/16/2020 05:26:27 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 05:26:29 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 05:26:29 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  32% 9323/29080 [40:13<1:24:55,  3.88it/s]\u001b[A\n",
            "Iteration:  35% 10103/29080 [43:23<1:21:25,  3.88it/s]\u001b[A\n",
            "Iteration:  35% 10103/29080 [43:33<1:21:25,  3.88it/s]\u001b[A\n",
            "Iteration:  37% 10868/29080 [46:43<1:18:32,  3.86it/s]\u001b[A\n",
            "Iteration:  37% 10868/29080 [47:03<1:18:32,  3.86it/s]\u001b[A\n",
            "Iteration:  40% 11555/29080 [50:03<1:18:26,  3.72it/s]\u001b[A\n",
            "Iteration:  40% 11555/29080 [50:23<1:18:26,  3.72it/s]\u001b[A\n",
            "Iteration:  42% 12341/29080 [53:23<1:13:45,  3.78it/s]\u001b[A\n",
            "Iteration:  42% 12341/29080 [53:43<1:13:45,  3.78it/s]\u001b[A\n",
            "Iteration:  45% 13050/29080 [56:44<1:12:05,  3.71it/s]\u001b[A\n",
            "Iteration:  45% 13050/29080 [57:03<1:12:05,  3.71it/s]\u001b[A\n",
            "Iteration:  48% 13873/29080 [1:00:04<1:06:21,  3.82it/s]\u001b[A\n",
            "Iteration:  48% 13873/29080 [1:00:23<1:06:21,  3.82it/s]\u001b[A\n",
            "Iteration:  50% 14641/29080 [1:03:24<1:02:56,  3.82it/s]\u001b[A\n",
            "Iteration:  50% 14641/29080 [1:03:43<1:02:56,  3.82it/s]\u001b[A\n",
            "Iteration:  53% 15439/29080 [1:06:44<58:43,  3.87it/s]  \u001b[A\n",
            "Iteration:  53% 15439/29080 [1:07:03<58:43,  3.87it/s]\u001b[A\n",
            "Iteration:  56% 16232/29080 [1:10:05<54:57,  3.90it/s]\u001b[A\n",
            "Iteration:  56% 16232/29080 [1:10:23<54:57,  3.90it/s]\u001b[A\n",
            "Iteration:  59% 17073/29080 [1:13:25<50:14,  3.98it/s]\u001b[A\n",
            "Iteration:  59% 17073/29080 [1:13:43<50:14,  3.98it/s]\u001b[A\n",
            "Iteration:  62% 17912/29080 [1:16:45<46:02,  4.04it/s]\u001b[A\n",
            "Iteration:  62% 17912/29080 [1:17:03<46:02,  4.04it/s]\u001b[A\n",
            "Iteration:  64% 18664/29080 [1:20:06<43:55,  3.95it/s]\u001b[A\n",
            "Iteration:  64% 18664/29080 [1:20:23<43:55,  3.95it/s]\u001b[A\n",
            "Iteration:  67% 19480/29080 [1:23:26<40:07,  3.99it/s]\u001b[A\n",
            "Iteration:  67% 19480/29080 [1:23:43<40:07,  3.99it/s]\u001b[A\n",
            "Iteration:  70% 20342/29080 [1:26:46<35:42,  4.08it/s]\u001b[A\n",
            "Iteration:  70% 20342/29080 [1:27:03<35:42,  4.08it/s]\u001b[A\n",
            "Iteration:  72% 21056/29080 [1:30:06<34:11,  3.91it/s]\u001b[A\n",
            "Iteration:  72% 21056/29080 [1:30:23<34:11,  3.91it/s]\u001b[A\n",
            "Iteration:  75% 21808/29080 [1:33:26<31:21,  3.86it/s]\u001b[A\n",
            "Iteration:  75% 21808/29080 [1:33:43<31:21,  3.86it/s]\u001b[A11/16/2020 06:21:06 - INFO - transformers.configuration_utils -   Configuration saved in game_bert_model_save_dir3/config.json\n",
            "11/16/2020 06:21:08 - INFO - transformers.modeling_utils -   Model weights saved in game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 06:21:08 - INFO - trainer -   Saving model checkpoint to game_bert_model_save_dir3\n",
            "\n",
            "Iteration:  78% 22568/29080 [1:36:48<28:18,  3.83it/s]\u001b[A\n",
            "Iteration:  78% 22568/29080 [1:37:03<28:18,  3.83it/s]\u001b[A\n",
            "Iteration:  80% 23370/29080 [1:40:08<24:30,  3.88it/s]\u001b[A\n",
            "Iteration:  80% 23370/29080 [1:40:23<24:30,  3.88it/s]\u001b[A\n",
            "Iteration:  83% 24081/29080 [1:43:29<22:04,  3.78it/s]\u001b[A\n",
            "Iteration:  83% 24081/29080 [1:43:43<22:04,  3.78it/s]\u001b[A\n",
            "Iteration:  86% 24920/29080 [1:46:50<17:50,  3.89it/s]\u001b[A\n",
            "Iteration:  86% 24920/29080 [1:47:03<17:50,  3.89it/s]\u001b[A\n",
            "Iteration:  89% 25802/29080 [1:50:10<13:33,  4.03it/s]\u001b[A\n",
            "Iteration:  89% 25802/29080 [1:50:23<13:33,  4.03it/s]\u001b[A\n",
            "Iteration:  92% 26610/29080 [1:53:30<10:12,  4.03it/s]\u001b[A\n",
            "Iteration:  92% 26610/29080 [1:53:43<10:12,  4.03it/s]\u001b[A\n",
            "Iteration:  94% 27370/29080 [1:56:50<07:11,  3.96it/s]\u001b[A\n",
            "Iteration:  94% 27370/29080 [1:57:03<07:11,  3.96it/s]\u001b[A\n",
            "Iteration:  97% 28304/29080 [2:00:10<03:07,  4.15it/s]\u001b[A\n",
            "Iteration: 100% 29080/29080 [2:03:17<00:00,  3.93it/s]\n",
            "Epoch: 100% 2/2 [4:08:04<00:00, 7442.34s/it]\n",
            "11/16/2020 06:49:37 - INFO - transformers.configuration_utils -   loading configuration file game_bert_model_save_dir3/config.json\n",
            "11/16/2020 06:49:37 - INFO - transformers.configuration_utils -   Model config BertConfig {\n",
            "  \"_num_labels\": 2,\n",
            "  \"architectures\": [\n",
            "    \"JointBERT\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"bos_token_id\": null,\n",
            "  \"decoder_start_token_id\": null,\n",
            "  \"do_sample\": false,\n",
            "  \"early_stopping\": false,\n",
            "  \"eos_token_id\": null,\n",
            "  \"finetuning_task\": \"standard_dota50k_context_depth=all\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"is_encoder_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"min_length\": 0,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"no_repeat_ngram_size\": 0,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"prefix\": null,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"task_specific_params\": null,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "11/16/2020 06:49:37 - INFO - transformers.modeling_utils -   loading weights file game_bert_model_save_dir3/pytorch_model.bin\n",
            "11/16/2020 06:49:39 - INFO - trainer -   ***** Model Loaded *****\n",
            "11/16/2020 06:49:39 - INFO - trainer -   ***** Running evaluation on test dataset *****\n",
            "11/16/2020 06:49:39 - INFO - trainer -     Num examples = 9687\n",
            "11/16/2020 06:49:39 - INFO - trainer -     Batch size = 1\n",
            "Evaluating: 100% 9687/9687 [15:08<00:00, 10.66it/s]\n",
            "11/16/2020 07:04:49 - INFO - trainer -   ***** Eval results *****\n",
            "11/16/2020 07:04:49 - INFO - trainer -     intent_acc = 0.9002787240631774\n",
            "11/16/2020 07:04:49 - INFO - trainer -     loss = 0.3260188435063336\n",
            "11/16/2020 07:04:49 - INFO - trainer -     sementic_frame_acc = 0.17249922576649118\n",
            "11/16/2020 07:04:49 - INFO - trainer -     slot_f1 = 0.02951896683616073\n",
            "11/16/2020 07:04:49 - INFO - trainer -     slot_precision = 0.042328042328042326\n",
            "11/16/2020 07:04:49 - INFO - trainer -     slot_recall = 0.0226613237529363\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}